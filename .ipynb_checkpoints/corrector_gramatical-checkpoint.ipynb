{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué es un corrector gramatical?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un sistema de revisión de textos, capaz de implementar reglas de análisis y corrección de textos basados en el idioma específico con el que se está trabajando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capacidad de corrección:\n",
    "\n",
    "Entre otras cosas, un correcto gramatical puede detectar lo siguiente:\n",
    "\n",
    "- Faltas de ortografía en palabras comunes  (Por fabor  →  Por favor) \n",
    "\n",
    "- Combinación incorrecta de singulares y plurales  (Mi casas  →  Mi casa)\n",
    "\n",
    "- Palabras repetidas (Le dije eso eso ayer  →  Le dije eso ayer)\n",
    "\n",
    "- Mayúsculas en lugares incorrectos  (LA tarDe  →  La tarde)\n",
    "\n",
    "- Problemas con verbos auxiliares (Debes pagado  →  Debes pagar)\n",
    "\n",
    "Entre otras aplicaciones\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAREA 01: Construir un corrector gramatical que revise en un texto errores como los que se detallan a continuación. Imprimir \n",
    "# el texto corregido marcando los cambios entre corchetes “[]” Mostrar la cantidad y tipo de correcciones realizadas:\n",
    "\n",
    "# Tips: \n",
    "#- Se debe utilizar un método por cada caso\n",
    "\n",
    "#- La tarea se trabajará directamente en un Jupyter Notebook y se deberá de poder ejecutar con la instalación realizada en \n",
    "# clase, y en caso de usar alguna librería adicional, especificarlo en el mismo notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: Hola q tal? Quiero ir aki pq tmb sta el msj dnd me dices sq viste algo x allá.\n",
      "Texto corregido: Hola [que] tal ? Quiero ir [aquí] [porque] [también] [esta] el [mensaje] [dónde] me dices [es que] viste algo [por] allá . \n",
      "Número de correcciones: 9\n"
     ]
    }
   ],
   "source": [
    "def corrector_ortografico(texto):\n",
    "    \"\"\"Esta función verifica la ortografía de las palabras en un texto y corrige errores.\n",
    "\n",
    "    Args:\n",
    "        texto: El texto que se va a revisar.\n",
    "\n",
    "    Returns:\n",
    "        El texto con los errores corregidos y el número de correcciones.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear un diccionario de palabras comúnmente mal escritas.\n",
    "    palabras_incorrectas = {\n",
    "        \"q\": \"que\",\n",
    "        \"x\": \"por\",\n",
    "        \"cmo\": \"cómo\",\n",
    "        \"dnd\": \"dónde\",\n",
    "        \"sq\": \"es que\",\n",
    "        \"sta\": \"esta\",\n",
    "        \"msj\": \"mensaje\",\n",
    "        \"aki\": \"aquí\",\n",
    "        \"tmb\": \"también\",\n",
    "        \"qro\": \"quiero\", \n",
    "        \"pq\": \"porque\"\n",
    "    }\n",
    "\n",
    "    # Crear un documento spaCy a partir del texto.\n",
    "    doc = nlp(texto)\n",
    "\n",
    "    texto_corregido = \"\"\n",
    "    num_correcciones = 0\n",
    "    for token in doc:\n",
    "        if token.text.lower() in palabras_incorrectas:\n",
    "            texto_corregido += \"[\" + palabras_incorrectas[token.text.lower()] + \"]\"\n",
    "            num_correcciones += 1\n",
    "        else:\n",
    "            texto_corregido += token.text\n",
    "\n",
    "        texto_corregido += \" \"\n",
    "\n",
    "    return texto_corregido, num_correcciones\n",
    "\n",
    "texto = \"Hola q tal? Quiero ir aki pq tmb sta el msj dnd me dices sq viste algo x allá.\"\n",
    "\n",
    "texto_corregido, num_correcciones = corrector_ortografico(texto)\n",
    "\n",
    "print(\"Texto original: {}\".format(texto))\n",
    "print(\"Texto corregido: {}\".format(texto_corregido))\n",
    "print(\"Número de correcciones: {}\".format(num_correcciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso 2: Verificar que no exista una palabra en singular, seguida de una en plural y al revés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: Los coche son rojos. Mi amigos es amable.\n",
      "Correcciones sugeridas:  [('coche', 'coches'), ('amigos', 'amigo')]\n",
      "Texto corregido: Los coches son rojos. Mi amigo es amable.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "text = \"Los coche son rojos. Mi amigos es amable.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "correcciones = []\n",
    "\n",
    "def correct_number_mismatches(doc):    \n",
    "    for i, token in enumerate(doc[:-1]):  # Usamos doc[:-1] para evitar acceder fuera de rango\n",
    "        next_tok = doc[i + 1]\n",
    "\n",
    "        \n",
    "        # Corregimos las comparaciones\n",
    "        if token.tag_ == 'DET' and token.text[-1] == 's' and next_tok.tag_ == 'NOUN' and next_tok.text[-1] != 's':\n",
    "            correcciones.append((next_tok.text, next_tok.text + 's'))\n",
    "        elif token.tag_=='DET' and token.text[-1] != 's' and next_tok.tag_ == 'NOUN' and next_tok.text[-1] == 's':\n",
    "            correcciones.append((next_tok.text, next_tok.text[:-1]))\n",
    "\n",
    "def apply_corrections(text, correcciones):\n",
    "    for original, corrected in correcciones:\n",
    "        text = text.replace(original, corrected)\n",
    "    return text\n",
    "\n",
    "correct_number_mismatches(doc)\n",
    "\n",
    "texto_corregido = apply_corrections(text, correcciones)\n",
    "print(\"Texto original:\", text)\n",
    "print('Correcciones sugeridas: ', correcciones)\n",
    "print(\"Texto corregido:\", texto_corregido)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso 3: Verificar que no exista la misma palabra dos veces seguidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: Estamos probando probando que no haya palabras palabras repetidas en este este texto\n",
      "Texto corregido: Estamos probando que no haya palabras repetidas en este texto\n",
      "Número de correcciones: 3\n"
     ]
    }
   ],
   "source": [
    "def no_repetir_palabras(texto):\n",
    "    \"\"\"Esta función verifica que no exista la misma palabra repetida dos veces seguidas en un texto.\n",
    "\n",
    "    Args:\n",
    "        texto: El texto a revisar.\n",
    "\n",
    "    Returns:\n",
    "        El texto con las correcciones y el número de correcciones.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear un documento spaCy a partir del texto.\n",
    "    doc = nlp(texto)\n",
    "\n",
    "    texto_corregido = \"\"\n",
    "    num_correcciones = 0\n",
    "\n",
    "    prev_token = None\n",
    "    for token in doc:\n",
    "        if prev_token is not None and token.text.lower() == prev_token.text.lower():\n",
    "            num_correcciones += 1\n",
    "            continue\n",
    "        else:\n",
    "            texto_corregido += token.text + \" \"\n",
    "            prev_token = token\n",
    "\n",
    "    return texto_corregido.strip(), num_correcciones\n",
    "\n",
    "texto = \"Estamos probando probando que no haya palabras palabras repetidas en este este texto\"\n",
    "\n",
    "texto_corregido, num_correcciones = no_repetir_palabras(texto)\n",
    "\n",
    "print(\"Texto original: {}\".format(texto))\n",
    "print(\"Texto corregido: {}\".format(texto_corregido))\n",
    "print(\"Número de correcciones: {}\".format(num_correcciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso 4: Verificar que la forma de un token no mezcle mayúsculas, minúsculas y dígitos, a menos que se trate de todo en mayúsculas para marcar siglas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El texto combina mayúsculas y minúsculas de manera incorrecta.\n"
     ]
    }
   ],
   "source": [
    "def check_token_case(token):\n",
    "    \"\"\"Verifica si el token cumple con la regla de mayúsculas y minúsculas.\n",
    "\n",
    "    Args:\n",
    "        token (Token): El token a verificar.\n",
    "\n",
    "    Returns:\n",
    "        bool: True si el token cumple con la regla, False si no.\n",
    "    \"\"\"\n",
    "    text = token.text\n",
    "\n",
    "    if text.isupper():  # Todo en mayúsculas (siglas están permitidas)\n",
    "        return True\n",
    "    elif text.islower():  # Todo en minúsculas\n",
    "        return True\n",
    "    elif text.isdigit():  # Solo dígitos\n",
    "        return True\n",
    "    else:\n",
    "        # Verificar que no tenga combinación de mayúsculas, minúsculas y dígitos\n",
    "        if any(char.islower() for char in text) and any(char.isupper() for char in text) or any(char.isdigit() for char in text):\n",
    "            return False\n",
    "    return True  # Cualquier otra combinación no especificada se considera válida\n",
    "\n",
    "def check_token_case_rule(text):\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if not check_token_case(token):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Ejemplo de uso para verificar regla de mayúsculas y minúsculas\n",
    "texto_mayus = \"Los gatos son animales\"\n",
    "if not check_token_case_rule(texto_mayus):\n",
    "    print(\"El texto combina mayúsculas y minúsculas de manera incorrecta.\")\n",
    "else:\n",
    "    print(\"El texto no combina mayúsculas y minúsculas de manera incorrecta.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso 5: Identificar cuando se escriben 2 “NOUNS” seguidos, pero no se trata de un NOMBRE propio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'pos_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m segundos_sustantivos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(texto_corregido)\n\u001b[1;32m     39\u001b[0m texto \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEl perro gato juegan en el parque\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 40\u001b[0m segundos_sustantivos, texto_corregido \u001b[38;5;241m=\u001b[39m \u001b[43mdetectar_dos_nouns_seguidos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSegundos sustantivos encontrados:\u001b[39m\u001b[38;5;124m\"\u001b[39m, segundos_sustantivos)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTexto original: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(texto))\n",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m, in \u001b[0;36mdetectar_dos_nouns_seguidos\u001b[0;34m(texto)\u001b[0m\n\u001b[1;32m     10\u001b[0m token_ant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token_ant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m token_ant\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOUN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtoken_ant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROPN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m token\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOUN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m token\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROPN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m token\u001b[38;5;241m.\u001b[39ment_type_ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPERSON\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m token_ant\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m!=\u001b[39m token\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m     14\u001b[0m             pares_sustantivos\u001b[38;5;241m.\u001b[39mappend((token_ant\u001b[38;5;241m.\u001b[39mi, token\u001b[38;5;241m.\u001b[39mi))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'pos_'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "def detectar_dos_nouns_seguidos(texto):\n",
    "    doc = nlp(texto)\n",
    "\n",
    "    # Lista de pares de sustantivos encontrados\n",
    "    pares_sustantivos = []\n",
    "\n",
    "    token_ant = None\n",
    "    for token in doc:\n",
    "        if token_ant is not None and token_ant.pos_ == \"NOUN\" or token_ant.pos_ == \"PROPN\" and token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\" and token.ent_type_ != \"PERSON\":\n",
    "            if token_ant.text.lower() != token.text.lower():\n",
    "                pares_sustantivos.append((token_ant.i, token.i))\n",
    "\n",
    "        print(token.pos_)\n",
    "        token_ant = token\n",
    "\n",
    "    # Construir texto corregido usando los pares identificados\n",
    "    texto_corregido = []\n",
    "    skip_next = False\n",
    "    for i, token in enumerate(doc):\n",
    "        if any([pair[0] == i for pair in pares_sustantivos]):\n",
    "            texto_corregido.append(\"[\" + token.text)\n",
    "            skip_next = True\n",
    "        elif any([pair[1] == i for pair in pares_sustantivos]):\n",
    "            texto_corregido.append(token.text + \"]\")\n",
    "            skip_next = False\n",
    "        elif skip_next:\n",
    "            continue\n",
    "        else:\n",
    "            texto_corregido.append(token.text)\n",
    "\n",
    "    # Obtener solo los segundos sustantivos de los pares\n",
    "    segundos_sustantivos = [doc[pair[1]].text for pair in pares_sustantivos]\n",
    "\n",
    "    return segundos_sustantivos, \" \".join(texto_corregido)\n",
    "\n",
    "texto = \"El perro gato juegan en el parque\"\n",
    "segundos_sustantivos, texto_corregido = detectar_dos_nouns_seguidos(texto)\n",
    "print(\"Segundos sustantivos encontrados:\", segundos_sustantivos)\n",
    "print(\"Texto original: {}\".format(texto))\n",
    "print(\"Texto corregido: {}\".format(texto_corregido))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
