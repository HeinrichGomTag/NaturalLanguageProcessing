{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué es un corrector gramatical?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un sistema de revisión de textos, capaz de implementar reglas de análisis y corrección de textos basados en el idioma específico con el que se está trabajando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capacidad de corrección:\n",
    "\n",
    "Entre otras cosas, un correcto gramatical puede detectar lo siguiente:\n",
    "\n",
    "- Faltas de ortografía en palabras comunes  (Por fabor  →  Por favor) \n",
    "\n",
    "- Combinación incorrecta de singulares y plurales  (Mi casas  →  Mi casa)\n",
    "\n",
    "- Palabras repetidas (Le dije eso eso ayer  →  Le dije eso ayer)\n",
    "\n",
    "- Mayúsculas en lugares incorrectos  (LA tarDe  →  La tarde)\n",
    "\n",
    "- Problemas con verbos auxiliares (Debes pagado  →  Debes pagar)\n",
    "\n",
    "Entre otras aplicaciones\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAREA 01: Construir un corrector gramatical que revise en un texto errores como los que se detallan a continuación. Imprimir \n",
    "# el texto corregido marcando los cambios entre corchetes “[]” Mostrar la cantidad y tipo de correcciones realizadas:\n",
    "\n",
    "# Tips: \n",
    "#- Se debe utilizar un método por cada caso\n",
    "\n",
    "#- La tarea se trabajará directamente en un Jupyter Notebook y se deberá de poder ejecutar con la instalación realizada en \n",
    "# clase, y en caso de usar alguna librería adicional, especificarlo en el mismo notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: Hola q tal? Quiero ir aki pq tmb sta el msj dnd me dices sq viste algo x allá.\n",
      "Texto corregido: Hola [que] tal ? Quiero ir [aquí] [porque] [también] [esta] el [mensaje] [dónde] me dices [es que] viste algo [por] allá . \n",
      "Número de correcciones: 9\n"
     ]
    }
   ],
   "source": [
    "def corrector_ortografico(texto):\n",
    "    \"\"\"Esta función verifica la ortografía de las palabras en un texto y corrige errores.\n",
    "\n",
    "    Args:\n",
    "        texto: El texto que se va a revisar.\n",
    "\n",
    "    Returns:\n",
    "        El texto con los errores corregidos y el número de correcciones.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear un diccionario de palabras comúnmente mal escritas.\n",
    "    palabras_incorrectas = {\n",
    "        \"q\": \"que\",\n",
    "        \"x\": \"por\",\n",
    "        \"cmo\": \"cómo\",\n",
    "        \"dnd\": \"dónde\",\n",
    "        \"sq\": \"es que\",\n",
    "        \"sta\": \"esta\",\n",
    "        \"msj\": \"mensaje\",\n",
    "        \"aki\": \"aquí\",\n",
    "        \"tmb\": \"también\",\n",
    "        \"qro\": \"quiero\", \n",
    "        \"pq\": \"porque\"\n",
    "    }\n",
    "\n",
    "    # Crear un documento spaCy a partir del texto.\n",
    "    doc = nlp(texto)\n",
    "\n",
    "    texto_corregido = \"\"\n",
    "    num_correcciones = 0\n",
    "    for token in doc:\n",
    "        if token.text.lower() in palabras_incorrectas:\n",
    "            texto_corregido += \"[\" + palabras_incorrectas[token.text.lower()] + \"]\"\n",
    "            num_correcciones += 1\n",
    "        else:\n",
    "            texto_corregido += token.text\n",
    "\n",
    "        texto_corregido += \" \"\n",
    "\n",
    "    return texto_corregido, num_correcciones\n",
    "\n",
    "texto = \"Hola q tal? Quiero ir aki pq tmb sta el msj dnd me dices sq viste algo x allá.\"\n",
    "\n",
    "texto_corregido, num_correcciones = corrector_ortografico(texto)\n",
    "\n",
    "print(\"Texto original: {}\".format(texto))\n",
    "print(\"Texto corregido: {}\".format(texto_corregido))\n",
    "print(\"Número de correcciones: {}\".format(num_correcciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso 2: Verificar que no exista una palabra en singular, seguida de una en plural y al revés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcciones sugeridas:  [('coche', 'coches'), ('amigos', 'amigo')]\n",
      "Texto original: Los coche son rojos. Mi amigos es amable.\n",
      "Texto corregido: Los coches son rojos. Mi amigo es amable.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "text = \"Los coche son rojos. Mi amigos es amable.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "correcciones = []\n",
    "\n",
    "def correct_number_mismatches(doc):    \n",
    "    for i, token in enumerate(doc[:-1]):  # Usamos doc[:-1] para evitar acceder fuera de rango\n",
    "        next_tok = doc[i + 1]\n",
    "\n",
    "        \n",
    "        # Corregimos las comparaciones\n",
    "        if token.tag_ == 'DET' and token.text[-1] == 's' and next_tok.tag_ == 'NOUN' and next_tok.text[-1] != 's':\n",
    "            correcciones.append((next_tok.text, next_tok.text + 's'))\n",
    "        elif token.tag_=='DET' and token.text[-1] != 's' and next_tok.tag_ == 'NOUN' and next_tok.text[-1] == 's':\n",
    "            correcciones.append((next_tok.text, next_tok.text[:-1]))\n",
    "\n",
    "def apply_corrections(text, correcciones):\n",
    "    for original, corrected in correcciones:\n",
    "        text = text.replace(original, corrected)\n",
    "    return text\n",
    "\n",
    "correct_number_mismatches(doc)\n",
    "\n",
    "texto_corregido = apply_corrections(text, correcciones)\n",
    "print(\"Texto original:\", text)\n",
    "print('Correcciones sugeridas: ', correcciones)\n",
    "print(\"Texto corregido:\", texto_corregido)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso 3: Verificar que no exista la misma palabra dos veces seguidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: Estamos probando probando que no haya palabras palabras repetidas en este este texto\n",
      "Texto corregido: Estamos probando que no haya palabras repetidas en este texto\n",
      "Número de correcciones: 3\n"
     ]
    }
   ],
   "source": [
    "def no_repetir_palabras(texto):\n",
    "    \"\"\"Esta función verifica que no exista la misma palabra repetida dos veces seguidas en un texto.\n",
    "\n",
    "    Args:\n",
    "        texto: El texto a revisar.\n",
    "\n",
    "    Returns:\n",
    "        El texto con las correcciones y el número de correcciones.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear un documento spaCy a partir del texto.\n",
    "    doc = nlp(texto)\n",
    "\n",
    "    texto_corregido = \"\"\n",
    "    num_correcciones = 0\n",
    "\n",
    "    prev_token = None\n",
    "    for token in doc:\n",
    "        if prev_token is not None and token.text.lower() == prev_token.text.lower():\n",
    "            num_correcciones += 1\n",
    "            continue\n",
    "        else:\n",
    "            texto_corregido += token.text + \" \"\n",
    "            prev_token = token\n",
    "\n",
    "    return texto_corregido.strip(), num_correcciones\n",
    "\n",
    "texto = \"Estamos probando probando que no haya palabras palabras repetidas en este este texto\"\n",
    "\n",
    "texto_corregido, num_correcciones = no_repetir_palabras(texto)\n",
    "\n",
    "print(\"Texto original: {}\".format(texto))\n",
    "print(\"Texto corregido: {}\".format(texto_corregido))\n",
    "print(\"Número de correcciones: {}\".format(num_correcciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso 4: Verificar que la forma de un token no mezcle mayúsculas, minúsculas y dígitos, a menos que se trate de todo en mayúsculas para marcar siglas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME solo mayúsculas en el incio, ya te dice si si están combinadas o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El texto no combina mayúsculas y minúsculas de manera incorrecta.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def check_token_case(token):\n",
    "    \"\"\"Verifica si el token cumple con la regla de mayúsculas y minúsculas.\n",
    "\n",
    "    Args:\n",
    "        token (Token): El token a verificar.\n",
    "\n",
    "    Returns:\n",
    "        bool: True si el token cumple con la regla, False si no.\n",
    "    \"\"\"\n",
    "    text = token.text\n",
    "\n",
    "    if text.isupper():  # Todo en mayúsculas (siglas están permitidas)\n",
    "        return True\n",
    "    elif text.islower():  # Todo en minúsculas\n",
    "        return True\n",
    "    elif text.isdigit():  # Solo dígitos\n",
    "        return True\n",
    "    else:\n",
    "        # Verificar que no tenga combinación de mayúsculas, minúsculas y dígitos\n",
    "        if any(char.islower() for char in text) and any(char.isupper() for char in text) or any(char.isdigit() for char in text):\n",
    "            return False\n",
    "    return True  # Cualquier otra combinación no especificada se considera válida\n",
    "\n",
    "def check_token_case_rule(text):\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if not check_token_case(token):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Ejemplo de uso para verificar regla de mayúsculas y minúsculas\n",
    "texto_mayus = \"los gatos son animales\"\n",
    "if not check_token_case_rule(texto_mayus):\n",
    "    print(\"El texto combina mayúsculas y minúsculas de manera incorrecta.\")\n",
    "else:\n",
    "    print(\"El texto no combina mayúsculas y minúsculas de manera incorrecta.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso 5: Identificar cuando se escriben 2 “NOUNS” seguidos, pero no se trata de un NOMBRE propio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segundos sustantivos encontrados: ['ciudad', 'año']\n",
      "Texto original: Este año ciudad, nos vamos a mudar a la ciudad año!\n",
      "Texto corregido: Este año , nos vamos a mudar a la ciudad !\n"
     ]
    }
   ],
   "source": [
    "def detectar_dos_nouns_seguidos(texto):\n",
    "    \"\"\"Esta función identifica pares de \"NOUNS\" seguidos que no son nombres propios y los corrige.\n",
    "\n",
    "    Args:\n",
    "        texto: El texto a revisar.\n",
    "\n",
    "    Returns:\n",
    "        Una lista de segundos sustantivos y el texto corregido sin los segundos sustantivos.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear un documento spaCy a partir del texto.\n",
    "    doc = nlp(texto)\n",
    "\n",
    "    segundos_sustantivos = []\n",
    "    texto_corregido = \"\"\n",
    "\n",
    "    token_ant = None\n",
    "    for token in doc:\n",
    "        if token_ant is not None and token_ant.pos_ == \"NOUN\" and token.pos_ == \"NOUN\" and token.ent_type_ != \"PERSON\":\n",
    "            if token_ant.text.lower() != token.text.lower():\n",
    "                segundos_sustantivos.append(token.text)\n",
    "                if token_ant.text in texto_corregido and token.text in texto_corregido:\n",
    "                    texto_corregido = texto_corregido.replace(token_ant.text + \" \" + token.text, \"[\" + token_ant.text + \" \" + token.text + \"]\", 1)\n",
    "            else:\n",
    "                texto_corregido += \" \" + token.text\n",
    "        else:\n",
    "            texto_corregido += \" \" + token.text\n",
    "        token_ant = token\n",
    "\n",
    "    return segundos_sustantivos, texto_corregido.strip()\n",
    "\n",
    "texto = \"Este año ciudad, nos vamos a mudar a la ciudad año!\"\n",
    "\n",
    "segundos_sustantivos, texto_corregido = detectar_dos_nouns_seguidos(texto)\n",
    "\n",
    "print(\"Segundos sustantivos encontrados:\", segundos_sustantivos)\n",
    "print(\"Texto original: {}\".format(texto))\n",
    "print(\"Texto corregido: {}\".format(texto_corregido))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
