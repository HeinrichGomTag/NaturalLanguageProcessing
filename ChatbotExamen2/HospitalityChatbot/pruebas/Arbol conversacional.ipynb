{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:06.067553300Z",
     "start_time": "2023-11-06T06:21:06.048385Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:10.631358Z",
     "iopub.status.busy": "2023-11-06T19:58:10.631358Z",
     "iopub.status.idle": "2023-11-06T19:58:28.035460Z",
     "shell.execute_reply": "2023-11-06T19:58:28.034453Z"
    },
    "id": "F27k_d1FqDwV",
    "outputId": "4dee50c0-ef32-481e-e812-099f12b10ba1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/enriquegomeztagle/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "import re\n",
    "import json\n",
    "import locale\n",
    "import platform\n",
    "from datetime import datetime\n",
    "import numpy\n",
    "\n",
    "if platform.system() == 'Linux':\n",
    "    locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "elif platform.system() == 'Windows':\n",
    "    locale.setlocale(locale.LC_TIME, 'Spanish_Spain.1252')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:06.925900Z",
     "start_time": "2023-11-06T06:21:06.894820100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.038454Z",
     "iopub.status.busy": "2023-11-06T19:58:28.038454Z",
     "iopub.status.idle": "2023-11-06T19:58:28.051464Z",
     "shell.execute_reply": "2023-11-06T19:58:28.050454Z"
    },
    "id": "ugsfnO0pqDwn"
   },
   "outputs": [],
   "source": [
    "# Lectura de formatos .json para entrenar cada modelo y asignación\n",
    "# de información correspondiente\n",
    "with open('Intenciones_NivelI.json', encoding='utf-8') as file:\n",
    "    data_NivelI = json.load(file)\n",
    "\n",
    "with open('Intenciones_NivelIIA.json', encoding='utf-8') as file:\n",
    "    data_NivelIIA = json.load(file)\n",
    "\n",
    "with open('Intenciones_NivelIIB.json', encoding='utf-8') as file:\n",
    "    data_NivelIIB = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:08.479155400Z",
     "start_time": "2023-11-06T06:21:08.438325100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.054461Z",
     "iopub.status.busy": "2023-11-06T19:58:28.054461Z",
     "iopub.status.idle": "2023-11-06T19:58:28.067487Z",
     "shell.execute_reply": "2023-11-06T19:58:28.066487Z"
    },
    "id": "HogXD3MyqDwx",
    "outputId": "50b17eeb-89c4-4ea0-cb93-a9b6635e4a4d"
   },
   "outputs": [],
   "source": [
    "NI = dict()\n",
    "NIIA = dict()\n",
    "NIIB = dict()\n",
    "\n",
    "for info in data_NivelI['intents']:\n",
    "    NI.setdefault(info['tag'], info['patterns'])\n",
    "\n",
    "for info in data_NivelIIA['intents']:\n",
    "    NIIA.setdefault(info['tag'], info['patterns'])\n",
    "\n",
    "for info in data_NivelIIB['intents']:\n",
    "    NIIB.setdefault(info['tag'], info['patterns'])\n",
    "\n",
    "# print(NI)\n",
    "# print(NIIA)\n",
    "# print(NIIB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:10.627190600Z",
     "start_time": "2023-11-06T06:21:10.601524900Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.070667Z",
     "iopub.status.busy": "2023-11-06T19:58:28.070667Z",
     "iopub.status.idle": "2023-11-06T19:58:28.082667Z",
     "shell.execute_reply": "2023-11-06T19:58:28.081698Z"
    },
    "id": "cKAqS2HpqDxU",
    "outputId": "7e9491b9-200f-44c7-ecb3-673edbf78cf6"
   },
   "outputs": [],
   "source": [
    "Y_NI = list()\n",
    "Y_NIIA = list()\n",
    "Y_NIIB = list()\n",
    "\n",
    "for clase, lista_textos in NI.items():\n",
    "    for text in lista_textos:\n",
    "        Y_NI.append(list(NI.keys()).index(clase))\n",
    "\n",
    "for clase, lista_textos in NIIA.items():\n",
    "    for text in lista_textos:\n",
    "        Y_NIIA.append(list(NIIA.keys()).index(clase))\n",
    "\n",
    "for clase, lista_textos in NIIB.items():\n",
    "    for text in lista_textos:\n",
    "        Y_NIIB.append(list(NIIB.keys()).index(clase))\n",
    "\n",
    "# print(\"Vector de salidas Y para N1:\")\n",
    "# print(Y_NI)\n",
    "# print(\"Vector de salidas Y para N2A:\")\n",
    "# print(Y_NIIA)\n",
    "# print(\"Vector de salidas Y para N2B:\")\n",
    "# print(Y_NIIB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:25.397141600Z",
     "start_time": "2023-11-06T06:21:25.375492900Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.084667Z",
     "iopub.status.busy": "2023-11-06T19:58:28.084667Z",
     "iopub.status.idle": "2023-11-06T19:58:28.098689Z",
     "shell.execute_reply": "2023-11-06T19:58:28.097700Z"
    },
    "id": "6EmAmUbVqDxn"
   },
   "outputs": [],
   "source": [
    "def quitar_stopwords(Textos):\n",
    "    X = list()\n",
    "    for sentence in Textos:\n",
    "        for stopword in stop_words:\n",
    "            sentence = sentence.replace(\" \" + stopword + \" \", \" \")\n",
    "        sentence = sentence.replace(\"á\", \"a\")\n",
    "        sentence = sentence.replace(\"é\", \"e\")\n",
    "        sentence = sentence.replace(\"í\", \"i\")\n",
    "        sentence = sentence.replace(\"ó\", \"o\")\n",
    "        sentence = sentence.replace(\"ú\", \"u\")\n",
    "\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "        sentence = sentence.lower()\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        result = tokenizer.tokenize(sentence)\n",
    "        X.append(TreebankWordDetokenizer().detokenize(result))\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:26.159078200Z",
     "start_time": "2023-11-06T06:21:26.110426200Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.101668Z",
     "iopub.status.busy": "2023-11-06T19:58:28.101668Z",
     "iopub.status.idle": "2023-11-06T19:58:28.129695Z",
     "shell.execute_reply": "2023-11-06T19:58:28.129695Z"
    },
    "id": "_8EIY5ZMqDxz"
   },
   "outputs": [],
   "source": [
    "Textos_NI = list()\n",
    "for Lista in NI.values():\n",
    "    for Texto in Lista:\n",
    "        Textos_NI.append(Texto)\n",
    "\n",
    "X_NI = quitar_stopwords(Textos_NI)\n",
    "\n",
    "Textos_NIIA = list()\n",
    "for Lista in NIIA.values():\n",
    "    for Texto in Lista:\n",
    "        Textos_NIIA.append(Texto)\n",
    "\n",
    "X_NIIA = quitar_stopwords(Textos_NIIA)\n",
    "\n",
    "Textos_NIIB = list()\n",
    "for Lista in NIIB.values():\n",
    "    for Texto in Lista:\n",
    "        Textos_NIIB.append(Texto)\n",
    "\n",
    "X_NIIB = quitar_stopwords(Textos_NIIB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:26.905556400Z",
     "start_time": "2023-11-06T06:21:26.871986600Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.132667Z",
     "iopub.status.busy": "2023-11-06T19:58:28.132667Z",
     "iopub.status.idle": "2023-11-06T19:58:28.145670Z",
     "shell.execute_reply": "2023-11-06T19:58:28.144700Z"
    },
    "id": "V_8rv5yPqDyX",
    "outputId": "6dae233e-db00-4936-c653-76e4bf3e746e"
   },
   "outputs": [],
   "source": [
    "# print(X_NI)\n",
    "# print(X_NIIA)\n",
    "# print(X_NIIB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:27.465643100Z",
     "start_time": "2023-11-06T06:21:27.438124500Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.148700Z",
     "iopub.status.busy": "2023-11-06T19:58:28.147695Z",
     "iopub.status.idle": "2023-11-06T19:58:28.160733Z",
     "shell.execute_reply": "2023-11-06T19:58:28.160733Z"
    },
    "id": "rVSHyayPqDyi"
   },
   "outputs": [],
   "source": [
    "maxlen = 5\n",
    "\n",
    "tokenizer_NI = Tokenizer(num_words=5000)\n",
    "tokenizer_NIIA = Tokenizer(num_words=5000)\n",
    "tokenizer_NIIB = Tokenizer(num_words=5000)\n",
    "\n",
    "tokenizer_NI.fit_on_texts(X_NI)\n",
    "X_NI_Tok = tokenizer_NI.texts_to_sequences(X_NI)\n",
    "tokenizer_NIIA.fit_on_texts(X_NIIA)\n",
    "X_NIIA_Tok = tokenizer_NIIA.texts_to_sequences(X_NIIA)\n",
    "tokenizer_NIIB.fit_on_texts(X_NIIB)\n",
    "X_NIIB_Tok = tokenizer_NIIB.texts_to_sequences(X_NIIB)\n",
    "\n",
    "\n",
    "X_NI_train = pad_sequences(X_NI_Tok, padding='post', maxlen=maxlen)\n",
    "X_NIIA_train = pad_sequences(X_NIIA_Tok, padding='post', maxlen=maxlen)\n",
    "X_NIIB_train = pad_sequences(X_NIIB_Tok, padding='post', maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:28.111502600Z",
     "start_time": "2023-11-06T06:21:28.080933300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.163702Z",
     "iopub.status.busy": "2023-11-06T19:58:28.163702Z",
     "iopub.status.idle": "2023-11-06T19:58:28.177328Z",
     "shell.execute_reply": "2023-11-06T19:58:28.176465Z"
    },
    "id": "lPCepYiWqDyr",
    "outputId": "cc179339-358f-4c64-96c8-9346a1a87bde"
   },
   "outputs": [],
   "source": [
    "# print(\"Matriz de entrada para NI:\")\n",
    "# print(X_NI_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:28.612445200Z",
     "start_time": "2023-11-06T06:21:28.586380800Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.179359Z",
     "iopub.status.busy": "2023-11-06T19:58:28.179359Z",
     "iopub.status.idle": "2023-11-06T19:58:28.193625Z",
     "shell.execute_reply": "2023-11-06T19:58:28.192608Z"
    },
    "id": "jrkhqGluqDy3",
    "outputId": "920cfd66-d0f2-46b0-d751-ff002f8cfd11"
   },
   "outputs": [],
   "source": [
    "# print(\"Matriz de entrada para NIIA:\")\n",
    "# print(X_NIIA_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:22:03.038060500Z",
     "start_time": "2023-11-06T06:22:03.015502100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.195622Z",
     "iopub.status.busy": "2023-11-06T19:58:28.195622Z",
     "iopub.status.idle": "2023-11-06T19:58:28.208792Z",
     "shell.execute_reply": "2023-11-06T19:58:28.207932Z"
    },
    "id": "gcndmB1GqDzI",
    "outputId": "fb8ab50c-bc4f-4ddb-d760-eeeda30c326e"
   },
   "outputs": [],
   "source": [
    "# print(\"Matriz de entrada para NIIB:\")\n",
    "# print(X_NIIB_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.253691Z",
     "start_time": "2023-11-06T06:22:03.875934300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.210821Z",
     "iopub.status.busy": "2023-11-06T19:58:28.210821Z",
     "iopub.status.idle": "2023-11-06T19:59:32.275012Z",
     "shell.execute_reply": "2023-11-06T19:59:32.273129Z"
    },
    "id": "KqwMAfx-qDzS"
   },
   "outputs": [],
   "source": [
    "embeddings_dictionary = dict()\n",
    "Embeddings_file = open('Word2Vect_Spanish.txt', encoding=\"utf8\")\n",
    "\n",
    "for linea in Embeddings_file:\n",
    "    caracts = linea.split()\n",
    "    palabra = caracts[0]\n",
    "    vector = asarray(caracts[1:], dtype='float32')\n",
    "    embeddings_dictionary[palabra] = vector\n",
    "Embeddings_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.267219300Z",
     "start_time": "2023-11-06T06:23:13.256700800Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.279007Z",
     "iopub.status.busy": "2023-11-06T19:59:32.277980Z",
     "iopub.status.idle": "2023-11-06T19:59:32.289431Z",
     "shell.execute_reply": "2023-11-06T19:59:32.288412Z"
    },
    "id": "StTQjg7rqDzb"
   },
   "outputs": [],
   "source": [
    "def Asignar_Embeddings(tokenizer, vocab_size):\n",
    "    embedding_matrix = zeros((vocab_size, 300))\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_dictionary.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector\n",
    "    return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.295258600Z",
     "start_time": "2023-11-06T06:23:13.271226100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.291432Z",
     "iopub.status.busy": "2023-11-06T19:59:32.291432Z",
     "iopub.status.idle": "2023-11-06T19:59:32.304506Z",
     "shell.execute_reply": "2023-11-06T19:59:32.303646Z"
    },
    "id": "eHCZerdtqDzh"
   },
   "outputs": [],
   "source": [
    "vocab_size_NI = len(tokenizer_NI.word_index) + 1\n",
    "embedding_matrix_NI = Asignar_Embeddings(tokenizer_NI, vocab_size_NI)\n",
    "\n",
    "vocab_size_NIIA = len(tokenizer_NIIA.word_index) + 1\n",
    "embedding_matrix_NIIA = Asignar_Embeddings(tokenizer_NIIA, vocab_size_NIIA)\n",
    "\n",
    "vocab_size_NIIB = len(tokenizer_NIIB.word_index) + 1\n",
    "embedding_matrix_NIIB = Asignar_Embeddings(tokenizer_NIIB, vocab_size_NIIB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.321546Z",
     "start_time": "2023-11-06T06:23:13.302802900Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.306578Z",
     "iopub.status.busy": "2023-11-06T19:59:32.306578Z",
     "iopub.status.idle": "2023-11-06T19:59:32.319667Z",
     "shell.execute_reply": "2023-11-06T19:59:32.318812Z"
    },
    "id": "5pWpDUTnqD0D"
   },
   "outputs": [],
   "source": [
    "def Definir_Modelos(vocab_size, embedding_matrix, X_train, labels):\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=X_train.shape[1],\n",
    "                                trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(len(labels), activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # print(model.summary())\n",
    "\n",
    "    # print(\"\\nPalabras en el vocabulario:\")\n",
    "    # print(vocab_size)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.498406600Z",
     "start_time": "2023-11-06T06:23:13.316530700Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.322769Z",
     "iopub.status.busy": "2023-11-06T19:59:32.321772Z",
     "iopub.status.idle": "2023-11-06T19:59:32.758483Z",
     "shell.execute_reply": "2023-11-06T19:59:32.757581Z"
    },
    "id": "0fagAWujqD0M",
    "outputId": "ebd13cee-1f44-450a-d8df-efb7a0db57ea"
   },
   "outputs": [],
   "source": [
    "model_NI = Definir_Modelos(vocab_size_NI, embedding_matrix_NI, X_NI_train, NI.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.678021100Z",
     "start_time": "2023-11-06T06:23:13.473148500Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.760436Z",
     "iopub.status.busy": "2023-11-06T19:59:32.760436Z",
     "iopub.status.idle": "2023-11-06T19:59:32.868849Z",
     "shell.execute_reply": "2023-11-06T19:59:32.867993Z"
    },
    "id": "gr9tY4nAqD0a",
    "outputId": "90ca207d-24e6-4705-a67b-e5f79ef0aa28"
   },
   "outputs": [],
   "source": [
    "model_NIIA = Definir_Modelos(vocab_size_NIIA, embedding_matrix_NIIA, X_NIIA_train, NIIA.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.788026300Z",
     "start_time": "2023-11-06T06:23:13.629863400Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.870878Z",
     "iopub.status.busy": "2023-11-06T19:59:32.870878Z",
     "iopub.status.idle": "2023-11-06T19:59:32.978890Z",
     "shell.execute_reply": "2023-11-06T19:59:32.978890Z"
    },
    "id": "2LOUkuR4qD0h",
    "outputId": "cce08e90-3504-4be2-9cfd-4561e05e3249"
   },
   "outputs": [],
   "source": [
    "model_NIIB = Definir_Modelos(vocab_size_NIIB, embedding_matrix_NIIB, X_NIIB_train, NIIB.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.821589300Z",
     "start_time": "2023-11-06T06:23:13.770433100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.982929Z",
     "iopub.status.busy": "2023-11-06T19:59:32.981935Z",
     "iopub.status.idle": "2023-11-06T19:59:32.994137Z",
     "shell.execute_reply": "2023-11-06T19:59:32.994137Z"
    },
    "id": "N4jIB2_jqD0p"
   },
   "outputs": [],
   "source": [
    "def Entrenar_Modelos(X_train, Y, model, labels):\n",
    "    train_labels = to_categorical(Y, num_classes=len(labels))\n",
    "    # print('Matriz de salidas')\n",
    "    # print(train_labels)\n",
    "\n",
    "    history = model.fit(X_train, train_labels, epochs=30, batch_size=1, verbose=1)\n",
    "\n",
    "    score = model.evaluate(X_train, train_labels, verbose=1)\n",
    "    # print(\"\\nTest Loss:\", score[0])\n",
    "    # print(\"Test Accuracy:\", score[1])\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:28.182774800Z",
     "start_time": "2023-11-06T06:23:13.788026300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.997108Z",
     "iopub.status.busy": "2023-11-06T19:59:32.996107Z",
     "iopub.status.idle": "2023-11-06T19:59:45.342758Z",
     "shell.execute_reply": "2023-11-06T19:59:45.342758Z"
    },
    "id": "Z-MVeuwKqD0w",
    "outputId": "59ec4dee-801c-4e1f-d15e-332fa2890a5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "71/71 [==============================] - 3s 4ms/step - loss: 1.4842 - accuracy: 0.2676\n",
      "Epoch 2/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.9092 - accuracy: 0.6056\n",
      "Epoch 3/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.8169\n",
      "Epoch 4/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1912 - accuracy: 0.9437\n",
      "Epoch 5/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1003 - accuracy: 0.9859\n",
      "Epoch 6/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9859\n",
      "Epoch 7/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1284 - accuracy: 0.9437\n",
      "Epoch 8/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1532 - accuracy: 0.9577\n",
      "Epoch 9/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.1550 - accuracy: 0.9718\n",
      "Epoch 16/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9859\n",
      "Epoch 17/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 8.1425e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 9.2314e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.1610 - accuracy: 0.9296\n",
      "Epoch 30/30\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history_NI = Entrenar_Modelos(X_NI_train, Y_NI, model_NI, NI.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:41.300867800Z",
     "start_time": "2023-11-06T06:23:28.173755200Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:45.346760Z",
     "iopub.status.busy": "2023-11-06T19:59:45.345761Z",
     "iopub.status.idle": "2023-11-06T19:59:56.731652Z",
     "shell.execute_reply": "2023-11-06T19:59:56.731652Z"
    },
    "id": "ILAqDd2wqD06",
    "outputId": "1b9cd1cd-aac4-4622-90c2-f8c2cc3e2387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 4ms/step - loss: 1.2960 - accuracy: 0.5091\n",
      "Epoch 2/30\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.7068 - accuracy: 0.8000\n",
      "Epoch 3/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.2594 - accuracy: 0.9273\n",
      "Epoch 4/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9818\n",
      "Epoch 8/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.9273\n",
      "Epoch 9/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 9.1825e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 9.6049e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 5.8566e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 6.4663e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 6.5978e-04 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.0081e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history_NIIA = Entrenar_Modelos(X_NIIA_train, Y_NIIA, model_NIIA, NIIA.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:49.250042200Z",
     "start_time": "2023-11-06T06:23:41.288348200Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:56.734653Z",
     "iopub.status.busy": "2023-11-06T19:59:56.734653Z",
     "iopub.status.idle": "2023-11-06T20:00:03.370269Z",
     "shell.execute_reply": "2023-11-06T20:00:03.370269Z"
    },
    "id": "YWlw-BCFqD1C",
    "outputId": "c0bafdb6-c70a-4cca-80b1-b3201fa5084e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 3ms/step - loss: 1.0909 - accuracy: 0.3182\n",
      "Epoch 2/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9375 - accuracy: 0.4091\n",
      "Epoch 3/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7658 - accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5090 - accuracy: 0.9091\n",
      "Epoch 5/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.1993 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0414 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 9.4554e-04 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 7.9648e-04 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 9.4498e-04 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 8.8869e-04 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 6.8851e-04 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 4.6512e-04 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 7.3854e-04 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4.4991e-04 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3.7280e-04 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4.2361e-04 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3.3399e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3.8823e-04 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 9.1571e-04 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2.5030e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3.8473e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2.1524e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6644e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.3859e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.4342e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 1.2622e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history_NIIB = Entrenar_Modelos(X_NIIB_train, Y_NIIB, model_NIIB, NIIB.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:49.282587500Z",
     "start_time": "2023-11-06T06:23:49.247025200Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.373269Z",
     "iopub.status.busy": "2023-11-06T20:00:03.373269Z",
     "iopub.status.idle": "2023-11-06T20:00:03.385269Z",
     "shell.execute_reply": "2023-11-06T20:00:03.385269Z"
    },
    "id": "jV7UPQIHqD1P"
   },
   "outputs": [],
   "source": [
    "def Grafica_Modelo(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Acc', 'Loss'])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:49.511540900Z",
     "start_time": "2023-11-06T06:23:49.262560800Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.388269Z",
     "iopub.status.busy": "2023-11-06T20:00:03.388269Z",
     "iopub.status.idle": "2023-11-06T20:00:03.401268Z",
     "shell.execute_reply": "2023-11-06T20:00:03.401268Z"
    },
    "id": "m7X-IjGsqD1W",
    "outputId": "f59a7610-4adb-4eba-ff5c-16d840add32d"
   },
   "outputs": [],
   "source": [
    "# Grafica_Modelo(history_NI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:49.705345Z",
     "start_time": "2023-11-06T06:23:49.513541Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.404268Z",
     "iopub.status.busy": "2023-11-06T20:00:03.404268Z",
     "iopub.status.idle": "2023-11-06T20:00:03.417272Z",
     "shell.execute_reply": "2023-11-06T20:00:03.417272Z"
    },
    "id": "sfir3uYHqD1h",
    "outputId": "381d747b-a309-466f-d4ae-3732d05f9363"
   },
   "outputs": [],
   "source": [
    "# Grafica_Modelo(history_NIIA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:49.905498200Z",
     "start_time": "2023-11-06T06:23:49.702341500Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.420272Z",
     "iopub.status.busy": "2023-11-06T20:00:03.420272Z",
     "iopub.status.idle": "2023-11-06T20:00:03.432775Z",
     "shell.execute_reply": "2023-11-06T20:00:03.432775Z"
    },
    "id": "le9epcUPqD1n",
    "outputId": "9adce420-b1da-4759-c948-4ec43f08f4e5"
   },
   "outputs": [],
   "source": [
    "# Grafica_Modelo(history_NIIB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "In7eWoTIqD1u"
   },
   "source": [
    "# Programación del Árbol conversacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.021414900Z",
     "start_time": "2023-11-06T06:23:49.909014900Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.435778Z",
     "iopub.status.busy": "2023-11-06T20:00:03.435778Z",
     "iopub.status.idle": "2023-11-06T20:00:03.448779Z",
     "shell.execute_reply": "2023-11-06T20:00:03.448779Z"
    },
    "id": "PCsNvV_oqD1y"
   },
   "outputs": [],
   "source": [
    "def instancer(inp, model, tags):\n",
    "    inp = inp.lower().replace(\"á\", \"a\").replace(\"é\", \"e\").replace(\"í\", \"i\").replace(\"ó\", \"o\")\n",
    "    inp = inp.replace(\"ú\", \"u\").replace(\"¿\", \"\").replace(\"?\", \"\")\n",
    "    txt = [inp]\n",
    "    seq = tokenizer_NI.texts_to_sequences(txt)\n",
    "    padded = pad_sequences(seq, maxlen=maxlen)\n",
    "\n",
    "    # print(\"Input shape before predict:\", padded.shape)\n",
    "    # print(\"Input data:\", padded)\n",
    "\n",
    "    results = model.predict(padded)\n",
    "    results_index = numpy.argmax(results)\n",
    "    tag = list(tags.keys())[results_index]\n",
    "    maxscore = numpy.max(results)\n",
    "    return tag, maxscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "global estado_actual\n",
    "global Tipo_Cuarto\n",
    "global Fecha_entrada\n",
    "global Fecha_salida\n",
    "global Num_huespedes\n",
    "global Servicio_deseado\n",
    "global Espacio_Apartado\n",
    "global Servicio_Pedido\n",
    "global Comida_Pedida\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.021414900Z",
     "start_time": "2023-11-06T06:23:49.920704300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.451779Z",
     "iopub.status.busy": "2023-11-06T20:00:03.451779Z",
     "iopub.status.idle": "2023-11-06T20:00:03.464779Z",
     "shell.execute_reply": "2023-11-06T20:00:03.464779Z"
    },
    "id": "hACpbGDKqD14"
   },
   "outputs": [],
   "source": [
    "\n",
    "def Activar_NI(user_input):\n",
    "    if user_input is None:\n",
    "        response = \"\"\n",
    "        return response, 'NI'\n",
    "\n",
    "    if user_input == \"AUTORES\":\n",
    "            response = \"Easter Egg: Elaborado por Mau y Kike\"\n",
    "            return response, 'NI'\n",
    "    \n",
    "    if user_input == \"MEJOR PROFE\":\n",
    "            response = \"Easter Egg: IRVING\"\n",
    "            return response, 'NI'\n",
    "    \n",
    "    if user_input == \"SALUDOS A MICH\":\n",
    "            response = \"Easter Egg: Saludos Miich, un gusto verte por acá\"\n",
    "            return response, 'NI'\n",
    "    \n",
    "    tag, maxscore = instancer(user_input, model_NI, NI)\n",
    "\n",
    "    if maxscore > 0.65 or user_input == 'salir':\n",
    "        if user_input == 'salir':\n",
    "            response = \"Hasta luego, fue un gusto hablar contigo\"\n",
    "            return response, 'salir'\n",
    "\n",
    "        if tag == 'Reservar_Habitacion':\n",
    "            next_state = 'NIIA1'\n",
    "            response = \"Entendido, estás interesado en reservar una habitación. ¿Qué tipo de habitación deseas?\"\n",
    "\n",
    "        elif tag == 'Servicio_hotel':\n",
    "            if user_input.count('Apartar_espacio') > 0:\n",
    "                next_state = 'NIIB1'\n",
    "            elif user_input.count('Servicio') > 0:\n",
    "                next_state = 'NIIB2'\n",
    "            elif user_input.count('Comida_bebida') > 0:\n",
    "                next_state = 'NIIB3'\n",
    "            else:\n",
    "                next_state = 'NIIB'\n",
    "            response = \"Claro, puedo ayudarte con los servicios del hotel. (pedir comida, apartar espacio,...)\"\n",
    "\n",
    "        elif tag == 'Historia_Hotel':\n",
    "            response = \"Desde su apertura en 1920 por el pionero Don Eduardo Mendoza, nuestro hotel es un ícono de la arquitectura Art Deco, diseñado por Carlos Fontana.\\nHa acogido a luminarias como la actriz Clara Estrella en los años 30 y fue el lugar de la histórica cumbre de paz en 1955. Cada habitación cuenta una historia; por ejemplo, la suite 204, donde el novelista Luis Montero escribió su obra maestra. Es un lugar donde la historia y la hospitalidad se encuentran en cada esquina.\"\n",
    "            next_state = 'NI'\n",
    "\n",
    "        elif tag == 'Atracciones_Cercanas':\n",
    "            response = \"En el corazón de la ciudad, nuestro hotel se encuentra a un corto trayecto del Parque Central y a unos minutos del Museo Nacional de Arte, perfecto para los entusiastas de la cultura. Para aquellos interesados en la historia, el Convento de San Francisco está a una caminata de distancia. No te pierdas el Mercado del Sol, ideal para saborear la cocina local y encontrar artesanías únicas. Además, ofrecemos excursiones al Castillo de San Lorenzo, un sitio histórico con vistas espectaculares, a solo media hora en coche.\"\n",
    "            next_state = 'NI'\n",
    "\n",
    "        elif tag == \"Famosos_hotel\":\n",
    "            response = \"Nuestro hotel ha sido un destino favorito para muchas personalidades destacadas a lo largo de los años. Entre los huéspedes ilustres, hemos tenido el placer de acoger a figuras como el actor ganador del Oscar Leonardo DiCaprio, la aclamada cantante Adele, y el empresario tecnológico Elon Musk. Además, leyendas del deporte como Serena Williams y estrellas de la talla de Beyoncé también han disfrutado de la exclusividad y el servicio de primera clase de nuestro establecimiento. Cada celebridad que nos visita añade un capítulo único a la rica historia de nuestro hotel, asegurando que no solo sea un lugar de lujo, sino también un espacio donde se cruzan caminos extraordinarios\"\n",
    "            next_state = 'NI'\n",
    "\n",
    "        else:\n",
    "            next_state = 'NI'\n",
    "            response = \"Puedes preguntarme sobre reservaciones, servicios del hotel, su historia o atracciones cercanas.\"\n",
    "\n",
    "        return response, next_state\n",
    "\n",
    "    else:\n",
    "        response = \"Lo siento, pero no entendí tu petición, ¿Podrías decirlo de otra forma?\"\n",
    "        return response, 'NI'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.021414900Z",
     "start_time": "2023-11-06T06:23:49.956780Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.468779Z",
     "iopub.status.busy": "2023-11-06T20:00:03.468779Z",
     "iopub.status.idle": "2023-11-06T20:00:03.480778Z",
     "shell.execute_reply": "2023-11-06T20:00:03.480778Z"
    },
    "id": "iK-5AY2LqD2E"
   },
   "outputs": [],
   "source": [
    "def Activar_NIIA(user_input):\n",
    "    if user_input is None:\n",
    "        response = \"Escribe 'reservar habitación' para confirmar\"\n",
    "        return response, 'NIIA'\n",
    "\n",
    "    tag, maxscore = instancer(user_input, model_NIIA, NIIA)\n",
    "\n",
    "    if maxscore > 0.2 or user_input == 'salir' or user_input == 'volver':\n",
    "        if user_input == 'volver':\n",
    "            next_state = 'NI'\n",
    "            response = \"Entendido, volviendo al menú principal.\"\n",
    "        elif user_input == 'salir':\n",
    "            response = \"Hasta luego, fue un gusto hablar contigo.\"\n",
    "            return response\n",
    "        else:\n",
    "            next_state = 'NIIA1'        \n",
    "\n",
    "        return response, next_state\n",
    "    else:\n",
    "        response = \"Lo siento, pero no entendí.. Puedes internatar de nuevo\"\n",
    "        \n",
    "        return response, 'NIIA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.021414900Z",
     "start_time": "2023-11-06T06:23:49.970318600Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.484780Z",
     "iopub.status.busy": "2023-11-06T20:00:03.483780Z",
     "iopub.status.idle": "2023-11-06T20:00:03.496780Z",
     "shell.execute_reply": "2023-11-06T20:00:03.496780Z"
    },
    "id": "4AopUVTyqD2V"
   },
   "outputs": [],
   "source": [
    "def Activar_NIIA1(user_input=None):\n",
    "    if user_input is None:\n",
    "        response = \"\"\n",
    "        return response, 'NIIA1'\n",
    "    \n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    tag, maxscore = instancer(user_input, model_NIIA, NIIA)\n",
    "\n",
    "    if maxscore > 0.5 or user_input == 'salir' or user_input == 'volver':\n",
    "        if user_input == 'volver':\n",
    "            next_state = 'NI'\n",
    "            response = \"Entendido, volviendo al menú principal.\"\n",
    "        elif user_input == 'salir':\n",
    "            response = \"Hasta luego, fue un gusto hablar contigo.\"\n",
    "            return response\n",
    "        elif 'estándar' in user_input or 'económica' in user_input:\n",
    "            response = \"Excelente, reservaremos una habitación estándar. ¿Para cuándo agendamos su entrada? (dd/mm/aaaa)\"\n",
    "            Tipo_Cuarto = \"Estándar\"\n",
    "            next_state = 'NIIA2'\n",
    "        elif 'suite' in user_input:\n",
    "            response = \"Excelente, reservaremos una habitación suite. ¿Para cuándo agendamos su entrada? (dd/mm/aaaa)\"\n",
    "            Tipo_Cuarto = \"Suite\"\n",
    "            next_state = 'NIIA2'\n",
    "        elif 'doble' in user_input or 'dos camas' in user_input:\n",
    "            response = \"Excelente, reservaremos una habitación doble. ¿Para cuándo agendamos su entrada? (dd/mm/aaaa)\"\n",
    "            Tipo_Cuarto = \"Doble\"\n",
    "            next_state = 'NIIA2'\n",
    "        elif 'familiar' in user_input:\n",
    "            response = \"Excelente, reservaremos una habitación familiar. ¿Para cuándo agendamos su entrada? (dd/mm/aaaa)\"\n",
    "            Tipo_Cuarto = \"Familiar\"\n",
    "            next_state = 'NIIA2'\n",
    "        elif 'deluxe' in user_input:\n",
    "            response = \"Excelente, reservaremos una habitación deluxe. ¿Para cuándo agendamos su entrada? (dd/mm/aaaa)\"\n",
    "            Tipo_Cuarto = \"Deluxe\"\n",
    "            next_state = 'NIIA2'\n",
    "        elif 'ofrecen' in user_input:\n",
    "            response = \"Ofrecemos los siguientes tipos de habitaciones: estándar, doble, familiar, suite, y deluxe.\"\n",
    "        elif user_input == 'volver':\n",
    "            next_state = 'NIIA'\n",
    "            response = \"De acuerdo, volviendo al menú anterior.\"\n",
    "        elif user_input == 'salir':\n",
    "            next_state = 'salir'\n",
    "            response = \"Hasta luego, fue un gusto ayudarte.\"\n",
    "        else:\n",
    "            next_state = 'NIIA1'\n",
    "            response = \"No he podido identificar el tipo de habitación. ¿Puedes especificar si deseas una habitación estándar, suite, doble, etc.?\"\n",
    "\n",
    "        return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.021414900Z",
     "start_time": "2023-11-06T06:23:49.988344900Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.500782Z",
     "iopub.status.busy": "2023-11-06T20:00:03.500782Z",
     "iopub.status.idle": "2023-11-06T20:00:03.512779Z",
     "shell.execute_reply": "2023-11-06T20:00:03.512779Z"
    },
    "id": "aDMr1CxZqD2p"
   },
   "outputs": [],
   "source": [
    "def Activar_NIIA2(user_input):\n",
    "    if user_input is None:\n",
    "        response = \"\"\n",
    "\n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    if user_input == 'volver':\n",
    "        next_state = 'NI'\n",
    "        response = \"De acuerdo, volviendo al menú anterior.\"\n",
    "    elif user_input == 'salir':\n",
    "        response = \"Hasta luego, fue un gusto hablar contigo.\"\n",
    "        next_state = 'salir'\n",
    "    else:\n",
    "        try:\n",
    "            fecha_entrada_usuario = datetime.strptime(user_input, '%d/%m/%Y')\n",
    "            if fecha_entrada_usuario.date() < datetime.now().date():\n",
    "                response = \"No puedes agendar una fecha en el pasado. Por favor, elige una fecha futura.\"\n",
    "                next_state = 'NIIA2'\n",
    "            else:\n",
    "                fecha_formateada = fecha_entrada_usuario.strftime('%d de %B del %Y')\n",
    "                response = f\"Muy bien, agendaré la entrada para el {fecha_formateada}. ¿Para cuándo agendamos su salida? (dd/mm/aaaa)\"\n",
    "                Fecha_entrada = fecha_entrada_usuario\n",
    "                next_state = 'NIIA3'\n",
    "        except ValueError:\n",
    "            response = \"Parece que la fecha no está en el formato correcto. Por favor, ingresa la fecha en formato dd/mm/aaaa.\"\n",
    "            next_state = 'NIIA2'\n",
    "\n",
    "    return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.021414900Z",
     "start_time": "2023-11-06T06:23:50.004870500Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.516780Z",
     "iopub.status.busy": "2023-11-06T20:00:03.516780Z",
     "iopub.status.idle": "2023-11-06T20:00:03.527787Z",
     "shell.execute_reply": "2023-11-06T20:00:03.527787Z"
    }
   },
   "outputs": [],
   "source": [
    "def Activar_NIIA3(user_input):\n",
    "    if user_input is None:\n",
    "        response = \"\"\n",
    "\n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    if user_input == 'volver':\n",
    "        next_state = 'NI'\n",
    "        response = \"De acuerdo, volviendo al menú anterior.\"\n",
    "    elif user_input == 'salir':\n",
    "        response = \"Hasta luego, fue un gusto hablar contigo.\"\n",
    "        next_state = 'salir'\n",
    "    else:\n",
    "        try:\n",
    "            fecha_salida_usuario = datetime.strptime(user_input, '%d/%m/%Y')\n",
    "            if fecha_salida_usuario.date() < datetime.now().date():\n",
    "                response = \"No puedes agendar una fecha de salida en el pasado. Por favor, elige una fecha futura.\"\n",
    "            else:\n",
    "                fecha_formateada = fecha_salida_usuario.strftime('%d de %B del %Y')\n",
    "                response = f\"Muy bien, agendaré la salida para el {fecha_formateada}. ¿Para cuántos huéspedes?\"\n",
    "                Fecha_salida = fecha_salida_usuario\n",
    "                next_state = 'NIIA4'\n",
    "        except ValueError:\n",
    "            response = \"Parece que la fecha no está en el formato correcto. Por favor, ingresa la fecha en formato dd/mm/aaaa.\"\n",
    "            next_state = 'NIIA3'\n",
    "\n",
    "    return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.046778300Z",
     "start_time": "2023-11-06T06:23:50.019902600Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.532292Z",
     "iopub.status.busy": "2023-11-06T20:00:03.530786Z",
     "iopub.status.idle": "2023-11-06T20:00:03.543297Z",
     "shell.execute_reply": "2023-11-06T20:00:03.543297Z"
    }
   },
   "outputs": [],
   "source": [
    "def Activar_NIIA4(user_input):\n",
    "    if user_input is None:\n",
    "        response = \"\"\n",
    "        return response, 'NI'\n",
    "\n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    if user_input == 'volver':\n",
    "        next_state = 'NI'\n",
    "        response = \"De acuerdo, volviendo al menú anterior.\"\n",
    "    elif user_input == 'salir':\n",
    "        response = \"Hasta luego, fue un gusto hablar contigo.\"\n",
    "        next_state = 'salir'\n",
    "    else:\n",
    "        response = \"Reservación completada.. Presiona 'CLEAR' para continuar\"\n",
    "        next_state = 'NI'\n",
    "\n",
    "    return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.079352300Z",
     "start_time": "2023-11-06T06:23:50.038262600Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.547298Z",
     "iopub.status.busy": "2023-11-06T20:00:03.547298Z",
     "iopub.status.idle": "2023-11-06T20:00:03.559298Z",
     "shell.execute_reply": "2023-11-06T20:00:03.559298Z"
    }
   },
   "outputs": [],
   "source": [
    "def Activar_NIIB(user_input=None):\n",
    "    if user_input is None:\n",
    "        response = \"\"\n",
    "\n",
    "    tag, maxscore = instancer(user_input, model_NIIB, NIIB)\n",
    "\n",
    "    if maxscore > 0.2 or user_input == 'salir' or user_input == 'volver':\n",
    "        if user_input == 'volver':\n",
    "            next_state = 'NI'\n",
    "            response = \"De acuerdo, volviendo al menú anterior.\"\n",
    "        elif user_input == 'salir':\n",
    "            response = \"Hasta luego, fue un gusto hablar contigo.\"\n",
    "            next_state = 'salir'\n",
    "        elif tag == 'Apartar_espacio':\n",
    "            next_state = 'NIIB1'\n",
    "            response = \"Excelente! Apartemos un espacio. ¿Qué tipo de espacio te gustaría reservar?\"\n",
    "        elif tag == 'Servicio':\n",
    "            next_state = 'NIIB2'\n",
    "            response = \"Con gusto! ¿Qué servicio le gustaría pedir\"\n",
    "        elif tag == 'Comida_bebida':\n",
    "            next_state = 'NIIB3'\n",
    "            response = \"Hora de comer! ¿Qué alimento o bebida le gustaría pedir?\"\n",
    "        else:\n",
    "            response = \"No estoy seguro de cómo ayudarte con eso. ¿Podrías especificar más tu solicitud?\"\n",
    "            next_state = 'NIIB'\n",
    "    else:\n",
    "        response = \"Lo siento, pero no entendí. ¿Podrías ser más específico?\"\n",
    "        next_state = 'NIIB'\n",
    "\n",
    "    return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.081353800Z",
     "start_time": "2023-11-06T06:23:50.052793300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.562297Z",
     "iopub.status.busy": "2023-11-06T20:00:03.562297Z",
     "iopub.status.idle": "2023-11-06T20:00:03.575298Z",
     "shell.execute_reply": "2023-11-06T20:00:03.575298Z"
    }
   },
   "outputs": [],
   "source": [
    "def Activar_NIIB1(user_input):\n",
    "    if user_input is None:\n",
    "        response = \"Creo que no dijiste nada, ¿Qué tipo de espacio te gustaría reservar?\"\n",
    "        next_state = 'NIIB1'\n",
    "        return response, next_state\n",
    "\n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    if user_input == 'volver':\n",
    "        next_state = 'NI'\n",
    "        response = \"De acuerdo, volviendo al menú anterior.\"\n",
    "    elif user_input == 'salir':\n",
    "        response = \"Hasta luego, fue un gusto hablar contigo.\"\n",
    "        next_state = 'salir'\n",
    "    elif 'alberca' in user_input:\n",
    "        response = \"Excelente, reservaremos la alberca. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Espacio_Apartado = \"alberca\"\n",
    "        next_state = 'NI'\n",
    "    elif 'gimnasio' in user_input:\n",
    "        response = \"Excelente, reservaremos el gimnasio. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Espacio_Apartado = \"gimnasio\"\n",
    "        next_state = 'NI'\n",
    "    elif 'eventos' in user_input or 'salon' in user_input:\n",
    "        response = \"Excelente, reservaremos el salón de eventos. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Espacio_Apartado = \"salón de eventos\"\n",
    "        next_state = 'NI'\n",
    "    elif 'terraza' in user_input:\n",
    "        response = \"Excelente, reservaremos la terraza. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Espacio_Apartado = \"terraza\"\n",
    "        next_state = 'NI'\n",
    "    elif 'spa' in user_input:\n",
    "        response = \"Excelente, reservaremos el spa. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Espacio_Apartado = \"spa\"\n",
    "        next_state = 'NI'\n",
    "    else:\n",
    "        response = \"¿Podrías repetirme qué tipo de espacio te gustaría reservar?\"\n",
    "        next_state = 'NIIB1'\n",
    "\n",
    "    return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.082356500Z",
     "start_time": "2023-11-06T06:23:50.065317100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.578297Z",
     "iopub.status.busy": "2023-11-06T20:00:03.578297Z",
     "iopub.status.idle": "2023-11-06T20:00:03.590344Z",
     "shell.execute_reply": "2023-11-06T20:00:03.590344Z"
    }
   },
   "outputs": [],
   "source": [
    "def Activar_NIIB2(user_input=None):\n",
    "    if user_input is None:\n",
    "        response = \"Creo que no dijiste nada, ¿Qué servicio le gustaría pedir?\"\n",
    "        next_state = 'NIIB2'\n",
    "        return response, next_state\n",
    "\n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    if user_input == 'volver':\n",
    "        next_state = 'NI'\n",
    "        response = \"De acuerdo, volviendo al menú anterior.\"\n",
    "    elif user_input == 'salir':\n",
    "        response = \"Hasta luego, fue un gusto hablar contigo.\"\n",
    "        next_state = 'salir'\n",
    "    elif user_input.count('limpiar') > 0:\n",
    "        response = \"Claro, enviaremos a alguien para limpiar la habitación. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Servicio_Pedido = \"limpieza de cuarto\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('toallas') > 0:\n",
    "        response = \"Ok, enviaremos toallas a su habitación. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Servicio_Pedido = \"toallas\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('jabón') > 0 or user_input.count('shampoo') > 0:\n",
    "        response = \"Seguro! enviaremos artículos de higiene personal a su cuarto. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Servicio_Pedido = \"higiene personal\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('equipaje') > 0 or user_input.count('maletas') > 0:\n",
    "        response = \"Mandaremos a alguien para apoyar con el equipaje. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Servicio_Pedido = \"apoyo con equipaje\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('almohadas') > 0:\n",
    "        response = \"Con gusto enviaremos más almohadas a la habitación. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Servicio_Pedido = \"almohadas\"\n",
    "        next_state = 'NI'\n",
    "    else:\n",
    "        response = \"¿Podrías repetirme qué servicio requieres?\"\n",
    "        next_state = 'NIIB2'\n",
    "\n",
    "    return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.102389Z",
     "start_time": "2023-11-06T06:23:50.081353800Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.593383Z",
     "iopub.status.busy": "2023-11-06T20:00:03.593383Z",
     "iopub.status.idle": "2023-11-06T20:00:03.605691Z",
     "shell.execute_reply": "2023-11-06T20:00:03.605691Z"
    }
   },
   "outputs": [],
   "source": [
    "def Activar_NIIB3(user_input=None):\n",
    "    if user_input is None:\n",
    "        response = \"Creo que no dijiste nada, ¿Qué alimento o bebida le gustaría pedir?\"\n",
    "        next_state = 'NIIB3'\n",
    "        return response, next_state\n",
    "\n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    if user_input == 'volver':\n",
    "        next_state = 'NI'\n",
    "        response = \"De acuerdo, volviendo al menú anterior.\"\n",
    "    elif user_input == 'salir':\n",
    "        response = \"Hasta luego, fue un gusto hablar contigo.\"\n",
    "        next_state = 'salir'\n",
    "    elif user_input.count('desayuno') > 0:\n",
    "        response = \"Claro, enviaremos el desayuno a la habitación.\"\n",
    "        comida_pedida = \"desayuno\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('vegana') > 0 or user_input.count('vegetariana') > 0:\n",
    "        response = \"Por supuesto, prepararemos una opción vegana/vegetariana para usted.\"\n",
    "        comida_pedida = \"vegana/vegetariana\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('comida') > 0:\n",
    "        response = \"Mandaremos la comida a la habitación.\"\n",
    "        comida_pedida = \"comida\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('botella') > 0 or user_input.count('vino') > 0:\n",
    "        response = \"Seguro! enviaremos una botella de vino.\"\n",
    "        comida_pedida = \"vino\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('café') > 0:\n",
    "        response = \"Con gusto enviaremos café a su habitación.\"\n",
    "        comida_pedida = \"café\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('romántica') > 0:\n",
    "        response = \"Prepararemos una cena romántica para usted.\"\n",
    "        comida_pedida = \"romántica\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('cena') > 0:\n",
    "        response = \"Claro, mandaremos la cena a la habitación.\"\n",
    "        comida_pedida = \"cena\"\n",
    "        next_state = 'NI'\n",
    "    else:\n",
    "        response = \"¿Podrías repetirme qué alimento/bebida quieres pedir?\"\n",
    "        next_state = 'NIIB3'\n",
    "\n",
    "    return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:56:40.993042500Z",
     "start_time": "2023-11-06T06:56:40.418122200Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.608756Z",
     "iopub.status.busy": "2023-11-06T20:00:03.607754Z",
     "iopub.status.idle": "2023-11-06T20:00:03.858568Z",
     "shell.execute_reply": "2023-11-06T20:00:03.857713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7900\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7900/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 881,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 02:25:30.441197: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: indices[0,4] = 31 is not in [0, 30)\n",
      "\t [[{{node sequential_59/embedding_59/embedding_lookup}}]]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/routes.py\", line 534, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/blocks.py\", line 1185, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/utils.py\", line 661, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/3215818031.py\", line 30, in gradio_chatbot_function\n",
      "    response, next_state = adapted_chat1(user_input, state)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/3215818031.py\", line 23, in adapted_chat1\n",
      "    response, next_state = maquina_estados[Nivel](user_input)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/2725128997.py\", line 5, in Activar_NIIB\n",
      "    tag, maxscore = instancer(user_input, model_NIIB, NIIB)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/222794684.py\", line 11, in instancer\n",
      "    results = model.predict(padded)\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node 'sequential_59/embedding_59/embedding_lookup' defined at (most recent call last):\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/threading.py\", line 937, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "      self.run()\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "      result = context.run(func, *args)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/utils.py\", line 661, in wrapper\n",
      "      response = f(*args, **kwargs)\n",
      "    File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/3215818031.py\", line 30, in gradio_chatbot_function\n",
      "      response, next_state = adapted_chat1(user_input, state)\n",
      "    File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/3215818031.py\", line 23, in adapted_chat1\n",
      "      response, next_state = maquina_estados[Nivel](user_input)\n",
      "    File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/3837246269.py\", line 7, in Activar_NIIB\n",
      "      tag, maxscore = instancer(user_input, model_NIIB, NIIB)\n",
      "    File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/222794684.py\", line 11, in instancer\n",
      "      results = model.predict(padded)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2382, in predict\n",
      "      tmp_batch_outputs = self.predict_function(iterator)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2169, in predict_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2155, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2143, in run_step\n",
      "      outputs = model.predict_step(data)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in predict_step\n",
      "      return self(x, training=False)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n",
      "      return super().call(inputs, training=training, mask=mask)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/layers/core/embedding.py\", line 272, in call\n",
      "      out = tf.nn.embedding_lookup(self.embeddings, inputs)\n",
      "Node: 'sequential_59/embedding_59/embedding_lookup'\n",
      "indices[0,4] = 31 is not in [0, 30)\n",
      "\t [[{{node sequential_59/embedding_59/embedding_lookup}}]] [Op:__inference_predict_function_594131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 02:26:14.936578: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: indices[0,4] = 31 is not in [0, 30)\n",
      "\t [[{{node sequential_59/embedding_59/embedding_lookup}}]]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/routes.py\", line 534, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/blocks.py\", line 1185, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/utils.py\", line 661, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/3215818031.py\", line 30, in gradio_chatbot_function\n",
      "    response, next_state = adapted_chat1(user_input, state)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/3215818031.py\", line 23, in adapted_chat1\n",
      "    response, next_state = maquina_estados[Nivel](user_input)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/2725128997.py\", line 5, in Activar_NIIB\n",
      "    tag, maxscore = instancer(user_input, model_NIIB, NIIB)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/222794684.py\", line 11, in instancer\n",
      "    results = model.predict(padded)\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node 'sequential_59/embedding_59/embedding_lookup' defined at (most recent call last):\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/threading.py\", line 937, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "      self.run()\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "      result = context.run(func, *args)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/utils.py\", line 661, in wrapper\n",
      "      response = f(*args, **kwargs)\n",
      "    File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/3215818031.py\", line 30, in gradio_chatbot_function\n",
      "      response, next_state = adapted_chat1(user_input, state)\n",
      "    File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/3215818031.py\", line 23, in adapted_chat1\n",
      "      response, next_state = maquina_estados[Nivel](user_input)\n",
      "    File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/3837246269.py\", line 7, in Activar_NIIB\n",
      "      tag, maxscore = instancer(user_input, model_NIIB, NIIB)\n",
      "    File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/222794684.py\", line 11, in instancer\n",
      "      results = model.predict(padded)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2382, in predict\n",
      "      tmp_batch_outputs = self.predict_function(iterator)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2169, in predict_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2155, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2143, in run_step\n",
      "      outputs = model.predict_step(data)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in predict_step\n",
      "      return self(x, training=False)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n",
      "      return super().call(inputs, training=training, mask=mask)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/layers/core/embedding.py\", line 272, in call\n",
      "      out = tf.nn.embedding_lookup(self.embeddings, inputs)\n",
      "Node: 'sequential_59/embedding_59/embedding_lookup'\n",
      "indices[0,4] = 31 is not in [0, 30)\n",
      "\t [[{{node sequential_59/embedding_59/embedding_lookup}}]] [Op:__inference_predict_function_594131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# Implementación de casos correspondientes para cada nivel del ChatBot\n",
    "# Nivel contextual inicial por defecto, el primero\n",
    "\n",
    "\n",
    "estado_actual = \"NI\"\n",
    "\n",
    "maquina_estados = {'NI': Activar_NI,\n",
    "                   \"NIIA\": Activar_NIIA,\n",
    "                   \"NIIA1\": Activar_NIIA1,\n",
    "                   \"NIIA2\": Activar_NIIA2,\n",
    "                   \"NIIA3\": Activar_NIIA3,\n",
    "                   \"NIIA4\": Activar_NIIA4,\n",
    "                   \"NIIB\": Activar_NIIB,\n",
    "                   \"NIIB1\": Activar_NIIB1,\n",
    "                   \"NIIB2\": Activar_NIIB2,\n",
    "                   \"NIIB3\": Activar_NIIB3\n",
    "                   }\n",
    "\n",
    "def adapted_chat1(user_input, Nivel):\n",
    "    if user_input == \"\":\n",
    "        response, next_state = maquina_estados[Nivel](None)\n",
    "    else:\n",
    "        response, next_state = maquina_estados[Nivel](user_input)\n",
    "    return response, next_state\n",
    "\n",
    "def gradio_chatbot_function(user_input, state='NI'):\n",
    "    if user_input == \"\":\n",
    "        response, next_state = adapted_chat1(None, state)\n",
    "    else:\n",
    "        response, next_state = adapted_chat1(user_input, state)\n",
    "    return response, next_state\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_chatbot_function,\n",
    "    inputs=[gr.Textbox(lines=2, label=\"Tu mensaje\", placeholder=\"Escribe tu mensaje aquí...\"), \"state\"],\n",
    "    outputs=[gr.Textbox(label=\"Respuesta del Chatbot\", placeholder=\"Puedes preguntarme sobre reservaciones, servicios del hotel, su historia o atracciones cercanas\"), \"state\"],\n",
    "    title=\"Hotel ESDAI Chatbot\",\n",
    "    description=\"Bienvenido a Hotel ESDAI Chatbot. ¿Qué deseas hacer?\",\n",
    "    allow_flagging='never'\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.384832900Z",
     "start_time": "2023-11-06T06:23:50.326861200Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.861559Z",
     "iopub.status.busy": "2023-11-06T20:00:03.860555Z",
     "iopub.status.idle": "2023-11-06T20:00:03.873829Z",
     "shell.execute_reply": "2023-11-06T20:00:03.873017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/routes.py\", line 534, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/blocks.py\", line 1185, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/utils.py\", line 661, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/3215818031.py\", line 30, in gradio_chatbot_function\n",
      "    response, next_state = adapted_chat1(user_input, state)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/3215818031.py\", line 23, in adapted_chat1\n",
      "    response, next_state = maquina_estados[Nivel](user_input)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_8245/1903986933.py\", line 18, in Activar_NIIA3\n",
      "    elif Fecha_entrada and fecha_salida_usuario.date() <= Fecha_entrada.date():\n",
      "NameError: name 'Fecha_entrada' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "# # Check the size of the tokenizer's word index\n",
    "# print(\"Tokenizer word index size:\", len(tokenizer_NI.word_index))\n",
    "# \n",
    "# # After loading the model, check the input dimension of the embedding layer\n",
    "# embedding_input_dim = model_NIIB.layers[0].get_config()['input_dim']\n",
    "# print(\"Model's embedding input dimension:\", embedding_input_dim)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Reto 28.- Flujos conversaconales",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
