{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:06.067553300Z",
     "start_time": "2023-11-06T06:21:06.048385Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:10.631358Z",
     "iopub.status.busy": "2023-11-06T19:58:10.631358Z",
     "iopub.status.idle": "2023-11-06T19:58:28.035460Z",
     "shell.execute_reply": "2023-11-06T19:58:28.034453Z"
    },
    "id": "F27k_d1FqDwV",
    "outputId": "4dee50c0-ef32-481e-e812-099f12b10ba1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/enriquegomeztagle/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Enrique Ulises Báez Gómez Tagle && Mauricio Iván Ascencio Martínez\n",
    "# Importar nltk y tokenizadores necesarios para el procesamiento de texto.\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "\n",
    "import random\n",
    "\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "import re\n",
    "import json\n",
    "import locale\n",
    "import platform\n",
    "from datetime import datetime\n",
    "import numpy\n",
    "\n",
    "if platform.system() == 'Linux':\n",
    "    locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "elif platform.system() == 'Windows':\n",
    "    locale.setlocale(locale.LC_TIME, 'Spanish_Spain.1252')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:06.925900Z",
     "start_time": "2023-11-06T06:21:06.894820100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.038454Z",
     "iopub.status.busy": "2023-11-06T19:58:28.038454Z",
     "iopub.status.idle": "2023-11-06T19:58:28.051464Z",
     "shell.execute_reply": "2023-11-06T19:58:28.050454Z"
    },
    "id": "ugsfnO0pqDwn"
   },
   "outputs": [],
   "source": [
    "# Leer y asignar datos desde archivos JSON para entrenamiento de modelos.\n",
    "\n",
    "with open('Intenciones_NivelI.json', encoding='utf-8') as file:\n",
    "    data_NivelI = json.load(file)\n",
    "\n",
    "with open('Intenciones_NivelIIA.json', encoding='utf-8') as file:\n",
    "    data_NivelIIA = json.load(file)\n",
    "\n",
    "with open('Intenciones_NivelIIB.json', encoding='utf-8') as file:\n",
    "    data_NivelIIB = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:08.479155400Z",
     "start_time": "2023-11-06T06:21:08.438325100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.054461Z",
     "iopub.status.busy": "2023-11-06T19:58:28.054461Z",
     "iopub.status.idle": "2023-11-06T19:58:28.067487Z",
     "shell.execute_reply": "2023-11-06T19:58:28.066487Z"
    },
    "id": "HogXD3MyqDwx",
    "outputId": "50b17eeb-89c4-4ea0-cb93-a9b6635e4a4d"
   },
   "outputs": [],
   "source": [
    "# Crear diccionarios para almacenar intenciones en distintos niveles.\n",
    "NI = dict()\n",
    "NIIA = dict()\n",
    "NIIB = dict()\n",
    "\n",
    "for info in data_NivelI['intents']:\n",
    "    NI.setdefault(info['tag'], info['patterns'])\n",
    "\n",
    "for info in data_NivelIIA['intents']:\n",
    "    NIIA.setdefault(info['tag'], info['patterns'])\n",
    "\n",
    "for info in data_NivelIIB['intents']:\n",
    "    NIIB.setdefault(info['tag'], info['patterns'])\n",
    "\n",
    "# print(NI)\n",
    "# print(NIIA)\n",
    "# print(NIIB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:10.627190600Z",
     "start_time": "2023-11-06T06:21:10.601524900Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.070667Z",
     "iopub.status.busy": "2023-11-06T19:58:28.070667Z",
     "iopub.status.idle": "2023-11-06T19:58:28.082667Z",
     "shell.execute_reply": "2023-11-06T19:58:28.081698Z"
    },
    "id": "cKAqS2HpqDxU",
    "outputId": "7e9491b9-200f-44c7-ecb3-673edbf78cf6"
   },
   "outputs": [],
   "source": [
    "# Generar listas de etiquetas para clasificar las intenciones en los distintos niveles.\n",
    "Y_NI = list()\n",
    "Y_NIIA = list()\n",
    "Y_NIIB = list()\n",
    "\n",
    "for clase, lista_textos in NI.items():\n",
    "    for text in lista_textos:\n",
    "        Y_NI.append(list(NI.keys()).index(clase))\n",
    "\n",
    "for clase, lista_textos in NIIA.items():\n",
    "    for text in lista_textos:\n",
    "        Y_NIIA.append(list(NIIA.keys()).index(clase))\n",
    "\n",
    "for clase, lista_textos in NIIB.items():\n",
    "    for text in lista_textos:\n",
    "        Y_NIIB.append(list(NIIB.keys()).index(clase))\n",
    "\n",
    "# print(\"Vector de salidas Y para N1:\")\n",
    "# print(Y_NI)\n",
    "# print(\"Vector de salidas Y para N2A:\")\n",
    "# print(Y_NIIA)\n",
    "# print(\"Vector de salidas Y para N2B:\")\n",
    "# print(Y_NIIB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:25.397141600Z",
     "start_time": "2023-11-06T06:21:25.375492900Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.084667Z",
     "iopub.status.busy": "2023-11-06T19:58:28.084667Z",
     "iopub.status.idle": "2023-11-06T19:58:28.098689Z",
     "shell.execute_reply": "2023-11-06T19:58:28.097700Z"
    },
    "id": "6EmAmUbVqDxn"
   },
   "outputs": [],
   "source": [
    "# Definir función para eliminar stopwords de los textos.\n",
    "def quitar_stopwords(Textos):\n",
    "    X = list()\n",
    "    for sentence in Textos:\n",
    "        for stopword in stop_words:\n",
    "            sentence = sentence.replace(\" \" + stopword + \" \", \" \")\n",
    "        sentence = sentence.replace(\"á\", \"a\")\n",
    "        sentence = sentence.replace(\"é\", \"e\")\n",
    "        sentence = sentence.replace(\"í\", \"i\")\n",
    "        sentence = sentence.replace(\"ó\", \"o\")\n",
    "        sentence = sentence.replace(\"ú\", \"u\")\n",
    "\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "        sentence = sentence.lower()\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        result = tokenizer.tokenize(sentence)\n",
    "        X.append(TreebankWordDetokenizer().detokenize(result))\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:26.159078200Z",
     "start_time": "2023-11-06T06:21:26.110426200Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.101668Z",
     "iopub.status.busy": "2023-11-06T19:58:28.101668Z",
     "iopub.status.idle": "2023-11-06T19:58:28.129695Z",
     "shell.execute_reply": "2023-11-06T19:58:28.129695Z"
    },
    "id": "_8EIY5ZMqDxz"
   },
   "outputs": [],
   "source": [
    "# Recolectar textos sin stopwords para nivel I.\n",
    "Textos_NI = list()\n",
    "for Lista in NI.values():\n",
    "    for Texto in Lista:\n",
    "        Textos_NI.append(Texto)\n",
    "\n",
    "X_NI = quitar_stopwords(Textos_NI)\n",
    "\n",
    "Textos_NIIA = list()\n",
    "for Lista in NIIA.values():\n",
    "    for Texto in Lista:\n",
    "        Textos_NIIA.append(Texto)\n",
    "\n",
    "X_NIIA = quitar_stopwords(Textos_NIIA)\n",
    "\n",
    "Textos_NIIB = list()\n",
    "for Lista in NIIB.values():\n",
    "    for Texto in Lista:\n",
    "        Textos_NIIB.append(Texto)\n",
    "\n",
    "X_NIIB = quitar_stopwords(Textos_NIIB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:26.905556400Z",
     "start_time": "2023-11-06T06:21:26.871986600Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.132667Z",
     "iopub.status.busy": "2023-11-06T19:58:28.132667Z",
     "iopub.status.idle": "2023-11-06T19:58:28.145670Z",
     "shell.execute_reply": "2023-11-06T19:58:28.144700Z"
    },
    "id": "V_8rv5yPqDyX",
    "outputId": "6dae233e-db00-4936-c653-76e4bf3e746e"
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(X_NI)\n",
    "# print(X_NIIA)\n",
    "# print(X_NIIB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:27.465643100Z",
     "start_time": "2023-11-06T06:21:27.438124500Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.148700Z",
     "iopub.status.busy": "2023-11-06T19:58:28.147695Z",
     "iopub.status.idle": "2023-11-06T19:58:28.160733Z",
     "shell.execute_reply": "2023-11-06T19:58:28.160733Z"
    },
    "id": "rVSHyayPqDyi"
   },
   "outputs": [],
   "source": [
    "# Definir tokenizadores y preparar datos para entrenamiento de modelos.\n",
    "maxlen = 5\n",
    "\n",
    "tokenizer_NI = Tokenizer(num_words=5000)\n",
    "tokenizer_NIIA = Tokenizer(num_words=5000)\n",
    "tokenizer_NIIB = Tokenizer(num_words=5000)\n",
    "\n",
    "tokenizer_NI.fit_on_texts(X_NI)\n",
    "X_NI_Tok = tokenizer_NI.texts_to_sequences(X_NI)\n",
    "tokenizer_NIIA.fit_on_texts(X_NIIA)\n",
    "X_NIIA_Tok = tokenizer_NIIA.texts_to_sequences(X_NIIA)\n",
    "tokenizer_NIIB.fit_on_texts(X_NIIB)\n",
    "X_NIIB_Tok = tokenizer_NIIB.texts_to_sequences(X_NIIB)\n",
    "\n",
    "\n",
    "X_NI_train = pad_sequences(X_NI_Tok, padding='post', maxlen=maxlen)\n",
    "X_NIIA_train = pad_sequences(X_NIIA_Tok, padding='post', maxlen=maxlen)\n",
    "X_NIIB_train = pad_sequences(X_NIIB_Tok, padding='post', maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:28.111502600Z",
     "start_time": "2023-11-06T06:21:28.080933300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.163702Z",
     "iopub.status.busy": "2023-11-06T19:58:28.163702Z",
     "iopub.status.idle": "2023-11-06T19:58:28.177328Z",
     "shell.execute_reply": "2023-11-06T19:58:28.176465Z"
    },
    "id": "lPCepYiWqDyr",
    "outputId": "cc179339-358f-4c64-96c8-9346a1a87bde"
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(\"Matriz de entrada para NI:\")\n",
    "# print(X_NI_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:21:28.612445200Z",
     "start_time": "2023-11-06T06:21:28.586380800Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.179359Z",
     "iopub.status.busy": "2023-11-06T19:58:28.179359Z",
     "iopub.status.idle": "2023-11-06T19:58:28.193625Z",
     "shell.execute_reply": "2023-11-06T19:58:28.192608Z"
    },
    "id": "jrkhqGluqDy3",
    "outputId": "920cfd66-d0f2-46b0-d751-ff002f8cfd11"
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(\"Matriz de entrada para NIIA:\")\n",
    "# print(X_NIIA_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:22:03.038060500Z",
     "start_time": "2023-11-06T06:22:03.015502100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.195622Z",
     "iopub.status.busy": "2023-11-06T19:58:28.195622Z",
     "iopub.status.idle": "2023-11-06T19:58:28.208792Z",
     "shell.execute_reply": "2023-11-06T19:58:28.207932Z"
    },
    "id": "gcndmB1GqDzI",
    "outputId": "fb8ab50c-bc4f-4ddb-d760-eeeda30c326e"
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(\"Matriz de entrada para NIIB:\")\n",
    "# print(X_NIIB_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.253691Z",
     "start_time": "2023-11-06T06:22:03.875934300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:58:28.210821Z",
     "iopub.status.busy": "2023-11-06T19:58:28.210821Z",
     "iopub.status.idle": "2023-11-06T19:59:32.275012Z",
     "shell.execute_reply": "2023-11-06T19:59:32.273129Z"
    },
    "id": "KqwMAfx-qDzS"
   },
   "outputs": [],
   "source": [
    "# Cargar y procesar el archivo de embeddings de palabras para el español.\n",
    "embeddings_dictionary = dict()\n",
    "Embeddings_file = open('Word2Vect_Spanish.txt', encoding=\"utf8\")\n",
    "\n",
    "for linea in Embeddings_file:\n",
    "    caracts = linea.split()\n",
    "    palabra = caracts[0]\n",
    "    vector = asarray(caracts[1:], dtype='float32')\n",
    "    embeddings_dictionary[palabra] = vector\n",
    "Embeddings_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.267219300Z",
     "start_time": "2023-11-06T06:23:13.256700800Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.279007Z",
     "iopub.status.busy": "2023-11-06T19:59:32.277980Z",
     "iopub.status.idle": "2023-11-06T19:59:32.289431Z",
     "shell.execute_reply": "2023-11-06T19:59:32.288412Z"
    },
    "id": "StTQjg7rqDzb"
   },
   "outputs": [],
   "source": [
    "# Definir función para asignar embeddings a palabras según el tokenizador.\n",
    "def Asignar_Embeddings(tokenizer, vocab_size):\n",
    "    embedding_matrix = zeros((vocab_size, 300))\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_dictionary.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector\n",
    "    return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.295258600Z",
     "start_time": "2023-11-06T06:23:13.271226100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.291432Z",
     "iopub.status.busy": "2023-11-06T19:59:32.291432Z",
     "iopub.status.idle": "2023-11-06T19:59:32.304506Z",
     "shell.execute_reply": "2023-11-06T19:59:32.303646Z"
    },
    "id": "eHCZerdtqDzh"
   },
   "outputs": [],
   "source": [
    "# Asignar matrices de embeddings a los diferentes niveles y preparar tokenizadores.\n",
    "vocab_size_NI = len(tokenizer_NI.word_index) + 1\n",
    "embedding_matrix_NI = Asignar_Embeddings(tokenizer_NI, vocab_size_NI)\n",
    "\n",
    "vocab_size_NIIA = len(tokenizer_NIIA.word_index) + 1\n",
    "embedding_matrix_NIIA = Asignar_Embeddings(tokenizer_NIIA, vocab_size_NIIA)\n",
    "\n",
    "vocab_size_NIIB = len(tokenizer_NIIB.word_index) + 1\n",
    "embedding_matrix_NIIB = Asignar_Embeddings(tokenizer_NIIB, vocab_size_NIIB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.321546Z",
     "start_time": "2023-11-06T06:23:13.302802900Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.306578Z",
     "iopub.status.busy": "2023-11-06T19:59:32.306578Z",
     "iopub.status.idle": "2023-11-06T19:59:32.319667Z",
     "shell.execute_reply": "2023-11-06T19:59:32.318812Z"
    },
    "id": "5pWpDUTnqD0D"
   },
   "outputs": [],
   "source": [
    "# Definir modelos de aprendizaje profundo para cada nivel de intención.\n",
    "def Definir_Modelos(vocab_size, embedding_matrix, X_train, labels):\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=X_train.shape[1],\n",
    "                                trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(len(labels), activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # print(model.summary())\n",
    "\n",
    "    # print(\"\\nPalabras en el vocabulario:\")\n",
    "    # print(vocab_size)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.498406600Z",
     "start_time": "2023-11-06T06:23:13.316530700Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.322769Z",
     "iopub.status.busy": "2023-11-06T19:59:32.321772Z",
     "iopub.status.idle": "2023-11-06T19:59:32.758483Z",
     "shell.execute_reply": "2023-11-06T19:59:32.757581Z"
    },
    "id": "0fagAWujqD0M",
    "outputId": "ebd13cee-1f44-450a-d8df-efb7a0db57ea"
   },
   "outputs": [],
   "source": [
    "\n",
    "model_NI = Definir_Modelos(vocab_size_NI, embedding_matrix_NI, X_NI_train, NI.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.678021100Z",
     "start_time": "2023-11-06T06:23:13.473148500Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.760436Z",
     "iopub.status.busy": "2023-11-06T19:59:32.760436Z",
     "iopub.status.idle": "2023-11-06T19:59:32.868849Z",
     "shell.execute_reply": "2023-11-06T19:59:32.867993Z"
    },
    "id": "gr9tY4nAqD0a",
    "outputId": "90ca207d-24e6-4705-a67b-e5f79ef0aa28"
   },
   "outputs": [],
   "source": [
    "\n",
    "model_NIIA = Definir_Modelos(vocab_size_NIIA, embedding_matrix_NIIA, X_NIIA_train, NIIA.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.788026300Z",
     "start_time": "2023-11-06T06:23:13.629863400Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.870878Z",
     "iopub.status.busy": "2023-11-06T19:59:32.870878Z",
     "iopub.status.idle": "2023-11-06T19:59:32.978890Z",
     "shell.execute_reply": "2023-11-06T19:59:32.978890Z"
    },
    "id": "2LOUkuR4qD0h",
    "outputId": "cce08e90-3504-4be2-9cfd-4561e05e3249"
   },
   "outputs": [],
   "source": [
    "\n",
    "model_NIIB = Definir_Modelos(vocab_size_NIIB, embedding_matrix_NIIB, X_NIIB_train, NIIB.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:13.821589300Z",
     "start_time": "2023-11-06T06:23:13.770433100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.982929Z",
     "iopub.status.busy": "2023-11-06T19:59:32.981935Z",
     "iopub.status.idle": "2023-11-06T19:59:32.994137Z",
     "shell.execute_reply": "2023-11-06T19:59:32.994137Z"
    },
    "id": "N4jIB2_jqD0p"
   },
   "outputs": [],
   "source": [
    "# Entrenamiento de modelos\n",
    "def Entrenar_Modelos(X_train, Y, model, labels):\n",
    "    train_labels = to_categorical(Y, num_classes=len(labels))\n",
    "    # print('Matriz de salidas')\n",
    "    # print(train_labels)\n",
    "\n",
    "    history = model.fit(X_train, train_labels, epochs=30, batch_size=1, verbose=1)\n",
    "\n",
    "    score = model.evaluate(X_train, train_labels, verbose=1)\n",
    "    # print(\"\\nTest Loss:\", score[0])\n",
    "    # print(\"Test Accuracy:\", score[1])\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:28.182774800Z",
     "start_time": "2023-11-06T06:23:13.788026300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:32.997108Z",
     "iopub.status.busy": "2023-11-06T19:59:32.996107Z",
     "iopub.status.idle": "2023-11-06T19:59:45.342758Z",
     "shell.execute_reply": "2023-11-06T19:59:45.342758Z"
    },
    "id": "Z-MVeuwKqD0w",
    "outputId": "59ec4dee-801c-4e1f-d15e-332fa2890a5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "71/71 [==============================] - 1s 4ms/step - loss: 1.5160 - accuracy: 0.2958\n",
      "Epoch 2/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.9671 - accuracy: 0.7042\n",
      "Epoch 3/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.8592\n",
      "Epoch 4/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.2220 - accuracy: 0.9437\n",
      "Epoch 5/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.2630 - accuracy: 0.9014\n",
      "Epoch 6/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9577\n",
      "Epoch 7/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0990 - accuracy: 0.9577\n",
      "Epoch 9/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9859\n",
      "Epoch 10/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9577\n",
      "Epoch 24/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.9859\n",
      "Epoch 25/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 7.7547e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history_NI = Entrenar_Modelos(X_NI_train, Y_NI, model_NI, NI.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:41.300867800Z",
     "start_time": "2023-11-06T06:23:28.173755200Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:45.346760Z",
     "iopub.status.busy": "2023-11-06T19:59:45.345761Z",
     "iopub.status.idle": "2023-11-06T19:59:56.731652Z",
     "shell.execute_reply": "2023-11-06T19:59:56.731652Z"
    },
    "id": "ILAqDd2wqD06",
    "outputId": "1b9cd1cd-aac4-4622-90c2-f8c2cc3e2387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "55/55 [==============================] - 1s 4ms/step - loss: 1.3268 - accuracy: 0.4182\n",
      "Epoch 2/30\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.8229 - accuracy: 0.8727\n",
      "Epoch 3/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.3050 - accuracy: 0.9091\n",
      "Epoch 4/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.2593 - accuracy: 0.9273\n",
      "Epoch 5/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 9.7294e-04 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 6.0888e-04 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 7.4049e-04 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 4.9388e-04 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 4.9921e-04 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 3.5481e-04 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 3.3919e-04 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 4.0720e-04 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 3.9985e-04 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 2.7919e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 2.1703e-04 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 2.2035e-04 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 2.4715e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 2.4062e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 1.4650e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 1.6241e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 1.3245e-04 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0312e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history_NIIA = Entrenar_Modelos(X_NIIA_train, Y_NIIA, model_NIIA, NIIA.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:49.250042200Z",
     "start_time": "2023-11-06T06:23:41.288348200Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T19:59:56.734653Z",
     "iopub.status.busy": "2023-11-06T19:59:56.734653Z",
     "iopub.status.idle": "2023-11-06T20:00:03.370269Z",
     "shell.execute_reply": "2023-11-06T20:00:03.370269Z"
    },
    "id": "YWlw-BCFqD1C",
    "outputId": "c0bafdb6-c70a-4cca-80b1-b3201fa5084e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "22/22 [==============================] - 1s 3ms/step - loss: 1.0760 - accuracy: 0.4091\n",
      "Epoch 2/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9311 - accuracy: 0.4545\n",
      "Epoch 3/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.5455\n",
      "Epoch 4/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.9545\n",
      "Epoch 5/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.1721 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 8.5282e-04 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 7.3755e-04 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 6.5686e-04 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4.2337e-04 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4.2025e-04 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3.7788e-04 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3.7668e-04 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2.9526e-04 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2.0596e-04 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3.6326e-04 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2.2615e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6704e-04 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2.2788e-04 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2.1101e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2.2871e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.3740e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1.1737e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.1602e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.2223e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 9.0642e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history_NIIB = Entrenar_Modelos(X_NIIB_train, Y_NIIB, model_NIIB, NIIB.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:49.282587500Z",
     "start_time": "2023-11-06T06:23:49.247025200Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.373269Z",
     "iopub.status.busy": "2023-11-06T20:00:03.373269Z",
     "iopub.status.idle": "2023-11-06T20:00:03.385269Z",
     "shell.execute_reply": "2023-11-06T20:00:03.385269Z"
    },
    "id": "jV7UPQIHqD1P"
   },
   "outputs": [],
   "source": [
    "# Función para evaluación de rendimiento\n",
    "def Grafica_Modelo(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Acc', 'Loss'])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:49.511540900Z",
     "start_time": "2023-11-06T06:23:49.262560800Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.388269Z",
     "iopub.status.busy": "2023-11-06T20:00:03.388269Z",
     "iopub.status.idle": "2023-11-06T20:00:03.401268Z",
     "shell.execute_reply": "2023-11-06T20:00:03.401268Z"
    },
    "id": "m7X-IjGsqD1W",
    "outputId": "f59a7610-4adb-4eba-ff5c-16d840add32d"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Grafica_Modelo(history_NI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:49.705345Z",
     "start_time": "2023-11-06T06:23:49.513541Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.404268Z",
     "iopub.status.busy": "2023-11-06T20:00:03.404268Z",
     "iopub.status.idle": "2023-11-06T20:00:03.417272Z",
     "shell.execute_reply": "2023-11-06T20:00:03.417272Z"
    },
    "id": "sfir3uYHqD1h",
    "outputId": "381d747b-a309-466f-d4ae-3732d05f9363"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Grafica_Modelo(history_NIIA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:49.905498200Z",
     "start_time": "2023-11-06T06:23:49.702341500Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.420272Z",
     "iopub.status.busy": "2023-11-06T20:00:03.420272Z",
     "iopub.status.idle": "2023-11-06T20:00:03.432775Z",
     "shell.execute_reply": "2023-11-06T20:00:03.432775Z"
    },
    "id": "le9epcUPqD1n",
    "outputId": "9adce420-b1da-4759-c948-4ec43f08f4e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Grafica_Modelo(history_NIIB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "In7eWoTIqD1u"
   },
   "source": [
    "# Programación del Árbol conversacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.021414900Z",
     "start_time": "2023-11-06T06:23:49.909014900Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.435778Z",
     "iopub.status.busy": "2023-11-06T20:00:03.435778Z",
     "iopub.status.idle": "2023-11-06T20:00:03.448779Z",
     "shell.execute_reply": "2023-11-06T20:00:03.448779Z"
    },
    "id": "PCsNvV_oqD1y"
   },
   "outputs": [],
   "source": [
    "# Instancer base para poder obtener un tag y su score maximo\n",
    "def instancer(inp, model, tags):\n",
    "    inp = inp.lower().replace(\"á\", \"a\").replace(\"é\", \"e\").replace(\"í\", \"i\").replace(\"ó\", \"o\")\n",
    "    inp = inp.replace(\"ú\", \"u\").replace(\"¿\", \"\").replace(\"?\", \"\")\n",
    "    txt = [inp]\n",
    "    seq = tokenizer_NI.texts_to_sequences(txt)\n",
    "    padded = pad_sequences(seq, maxlen=maxlen)\n",
    "\n",
    "    # print(\"Input shape before predict:\", padded.shape)\n",
    "    # print(\"Input data:\", padded)\n",
    "\n",
    "    results = model.predict(padded)\n",
    "    results_index = numpy.argmax(results)\n",
    "    tag = list(tags.keys())[results_index]\n",
    "    maxscore = numpy.max(results)\n",
    "    return tag, maxscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.021414900Z",
     "start_time": "2023-11-06T06:23:49.920704300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.451779Z",
     "iopub.status.busy": "2023-11-06T20:00:03.451779Z",
     "iopub.status.idle": "2023-11-06T20:00:03.464779Z",
     "shell.execute_reply": "2023-11-06T20:00:03.464779Z"
    },
    "id": "hACpbGDKqD14"
   },
   "outputs": [],
   "source": [
    "\n",
    "saludos_usuario = [\n",
    "    'hola', 'buenas noches', 'buenas tardes', 'buenos días', 'qué tal',\n",
    "    'qué onda', 'cómo estás', 'cómo va', 'cómo te va', 'qué pasa', \n",
    "    'qué más', 'cómo andas', 'cómo va todo', 'qué hay', 'cómo estáis',\n",
    "    'cómo están', 'qué hay de nuevo', 'qué se cuenta', 'cómo te ha ido',\n",
    "    'qué cuentas', 'cómo lo llevas', 'qué tal todo', 'qué tal estás',\n",
    "    'saludos', 'buen día', 'ey', 'ola', 'buenas', 'Hola'\n",
    "]\n",
    "\n",
    "saludos_chatbot = ['¡Hola! ¿Cómo puedo ayudarte?', 'Qué tal ¿en qué puedo asistirte?', 'Buenas, ¿cómo puedo servirte?', 'Hola de nuevo, ¿qué necesitas?', '¡Hola!']\n",
    "\n",
    "despedidas_usuario = [\n",
    "    'adiós', 'hasta luego', 'nos vemos', 'hasta pronto', 'hasta la vista',\n",
    "    'chao', 'bye', 'hasta mañana', 'hasta la próxima', 'me voy', 'me tengo que ir',\n",
    "    'tengo que irme', 'cuídate', 'te veo después', 'nos hablamos', 'hasta más tarde',\n",
    "    'hasta entonces', 'hasta después', 'que estés bien', 'que te vaya bien',\n",
    "    'cuidate mucho', 'te dejo', 'se me hace tarde', 'tengo que salir'\n",
    "]\n",
    "\n",
    "despedidas_chatbot = [\n",
    "    '¡Adiós! Espero haber sido de ayuda.', 'Hasta luego. Si necesitas algo más, aquí estaré.',\n",
    "    '¡Nos vemos! Que tengas un buen día.', 'Hasta pronto, ¡fue un placer asistirte!',\n",
    "    'Que te vaya bien. ¡Gracias por visitarnos!'\n",
    "]\n",
    "\n",
    "agradecimientos_usuario = [\n",
    "    'gracias', 'te agradezco', 'muchas gracias', 'agradecido', 'se agradece',\n",
    "    'aprecio tu ayuda', 'eres un sol', 'mil gracias', 'gracias por tu ayuda',\n",
    "    'gracias por todo', 'te lo agradezco mucho', 'te estoy muy agradecido',\n",
    "    'no sabes cuánto te lo agradezco', 'estoy agradecido', 'qué amable', 'eres muy amable'\n",
    "]\n",
    "\n",
    "agradecimientos_chatbot = [\n",
    "    '¡De nada! Siempre estoy aquí para ayudarte.', 'Fue un placer asistirte, ¡no hay de qué!',\n",
    "    'Me alegro de haber sido de ayuda, ¡gracias a ti!', 'Estoy aquí para lo que necesites, ¡gracias por tu amabilidad!',\n",
    "    '¡Gracias a ti por usar nuestro servicio!'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Nivel 1\n",
    "def Activar_NI(user_input):\n",
    "    if user_input is None:\n",
    "        response = \"\"\n",
    "        return response, 'NI'\n",
    "\n",
    "    if user_input == \"AUTORES\":\n",
    "            response = \"Easter Egg: Elaborado por Mau y Kike\"\n",
    "            return response, 'NI'\n",
    "    \n",
    "    if user_input == \"MEJOR PROFE\":\n",
    "            response = \"Easter Egg: IRVING\"\n",
    "            return response, 'NI'\n",
    "    \n",
    "    if user_input == \"SALUDOS A MICH\":\n",
    "            response = \"Easter Egg: Saludos Miich, un gusto verte por acá\"\n",
    "            return response, 'NI'\n",
    "    \n",
    "    if user_input in saludos_usuario:\n",
    "            response = random.choice(saludos_chatbot)\n",
    "            return response, 'NI'\n",
    "    \n",
    "    if user_input in agradecimientos_usuario:\n",
    "            response = random.choice(agradecimientos_chatbot)\n",
    "            return response, 'NI'\n",
    "    \n",
    "    if user_input in despedidas_usuario:\n",
    "            response = random.choice(despedidas_chatbot)\n",
    "            return response, 'NI'\n",
    "\n",
    "    tag, maxscore = instancer(user_input, model_NI, NI)\n",
    "\n",
    "    if maxscore > 0.65 or user_input == 'salir':\n",
    "\n",
    "        if tag == 'Reservar_Habitacion':\n",
    "            next_state = 'NIIA1'\n",
    "            response = \"Entendido, estás interesado en reservar una habitación. ¿Qué tipo de habitación deseas?\"\n",
    "\n",
    "        elif tag == 'Servicio_hotel':\n",
    "            if user_input.count('Apartar_espacio') > 0:\n",
    "                next_state = 'NIIB1'\n",
    "            elif user_input.count('Servicio') > 0:\n",
    "                next_state = 'NIIB2'\n",
    "            elif user_input.count('Comida_bebida') > 0:\n",
    "                next_state = 'NIIB3'\n",
    "            else:\n",
    "                next_state = 'NIIB'\n",
    "            response = \"Claro, puedo ayudarte con los servicios del hotel. (pedir comida, apartar espacio,...)\"\n",
    "\n",
    "        elif tag == 'Historia_Hotel':\n",
    "            response = \"Desde su apertura en 1920 por el pionero Don Eduardo Mendoza, nuestro hotel es un ícono de la arquitectura Art Deco, diseñado por Carlos Fontana.\\nHa acogido a luminarias como la actriz Clara Estrella en los años 30 y fue el lugar de la histórica cumbre de paz en 1955. Cada habitación cuenta una historia; por ejemplo, la suite 204, donde el novelista Luis Montero escribió su obra maestra. Es un lugar donde la historia y la hospitalidad se encuentran en cada esquina.\"\n",
    "            next_state = 'NI'\n",
    "\n",
    "        elif tag == 'Atracciones_Cercanas':\n",
    "            response = \"En el corazón de la ciudad, nuestro hotel se encuentra a un corto trayecto del Parque Central y a unos minutos del Museo Nacional de Arte, perfecto para los entusiastas de la cultura. Para aquellos interesados en la historia, el Convento de San Francisco está a una caminata de distancia. No te pierdas el Mercado del Sol, ideal para saborear la cocina local y encontrar artesanías únicas. Además, ofrecemos excursiones al Castillo de San Lorenzo, un sitio histórico con vistas espectaculares, a solo media hora en coche.\"\n",
    "            next_state = 'NI'\n",
    "\n",
    "        elif tag == \"Famosos_hotel\":\n",
    "            response = \"Nuestro hotel ha sido un destino favorito para muchas personalidades destacadas a lo largo de los años. Entre los huéspedes ilustres, hemos tenido el placer de acoger a figuras como el actor ganador del Oscar Leonardo DiCaprio, la aclamada cantante Adele, y el empresario tecnológico Elon Musk. Además, leyendas del deporte como Serena Williams y estrellas de la talla de Beyoncé también han disfrutado de la exclusividad y el servicio de primera clase de nuestro establecimiento. Cada celebridad que nos visita añade un capítulo único a la rica historia de nuestro hotel, asegurando que no solo sea un lugar de lujo, sino también un espacio donde se cruzan caminos extraordinarios\"\n",
    "            next_state = 'NI'\n",
    "\n",
    "        else:\n",
    "            next_state = 'NI'\n",
    "            response = \"Puedes preguntarme sobre reservaciones, servicios del hotel, su historia o atracciones cercanas.\"\n",
    "\n",
    "        return response, next_state\n",
    "\n",
    "    else:\n",
    "        response = \"Lo siento, pero no entendí tu petición, ¿Podrías decirlo de otra forma?\"\n",
    "        return response, 'NI'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.021414900Z",
     "start_time": "2023-11-06T06:23:49.956780Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.468779Z",
     "iopub.status.busy": "2023-11-06T20:00:03.468779Z",
     "iopub.status.idle": "2023-11-06T20:00:03.480778Z",
     "shell.execute_reply": "2023-11-06T20:00:03.480778Z"
    },
    "id": "iK-5AY2LqD2E"
   },
   "outputs": [],
   "source": [
    "# Nivel 2a\n",
    "def Activar_NIIA(user_input):\n",
    "    if user_input is None:\n",
    "        response = \"Escribe 'reservar habitación' para confirmar\"\n",
    "        return response, 'NIIA'\n",
    "        \n",
    "    if user_input in despedidas_usuario:\n",
    "            response = random.choice(despedidas_chatbot)\n",
    "            return response, 'NI'\n",
    "\n",
    "    tag, maxscore = instancer(user_input, model_NIIA, NIIA)\n",
    "\n",
    "    if maxscore > 0.7 or user_input == 'salir' or user_input == 'volver':\n",
    "        if user_input == 'volver':\n",
    "            next_state = 'NI'\n",
    "            response = \"Entendido, volviendo al menú principal.\"\n",
    "        elif user_input == 'salir':\n",
    "            response = \"Hasta luego, fue un gusto hablar contigo.\"\n",
    "            return response\n",
    "        else:\n",
    "            next_state = 'NIIA1'        \n",
    "\n",
    "        return response, next_state\n",
    "    else:\n",
    "        response = \"Lo siento, pero no entendí.. Puedes internatar de nuevo\"\n",
    "        \n",
    "        return response, 'NIIA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.021414900Z",
     "start_time": "2023-11-06T06:23:49.970318600Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.484780Z",
     "iopub.status.busy": "2023-11-06T20:00:03.483780Z",
     "iopub.status.idle": "2023-11-06T20:00:03.496780Z",
     "shell.execute_reply": "2023-11-06T20:00:03.496780Z"
    },
    "id": "4AopUVTyqD2V"
   },
   "outputs": [],
   "source": [
    "# Nivel 2a1\n",
    "def Activar_NIIA1(user_input=None):\n",
    "    if user_input is None:\n",
    "        response = \"\"\n",
    "        return response, 'NIIA1'\n",
    "    \n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    global Tipo_Cuarto\n",
    "        \n",
    "    if user_input in despedidas_usuario:\n",
    "        response = random.choice(despedidas_chatbot)\n",
    "        return response, 'NI'\n",
    "\n",
    "    tag, maxscore = instancer(user_input, model_NIIA, NIIA)\n",
    "\n",
    "    if maxscore > 0.5 or user_input == 'salir' or user_input == 'volver':\n",
    "        if 'estándar' in user_input or 'económica' in user_input:\n",
    "            response = \"Excelente, reservaremos una habitación estándar. ¿Para cuándo agendamos su entrada? (dd/mm/aaaa)\"\n",
    "            Tipo_Cuarto = \"Estándar\"\n",
    "            next_state = 'NIIA2'\n",
    "        elif 'suite' in user_input:\n",
    "            response = \"Excelente, reservaremos una habitación suite. ¿Para cuándo agendamos su entrada? (dd/mm/aaaa)\"\n",
    "            Tipo_Cuarto = \"Suite\"\n",
    "            next_state = 'NIIA2'\n",
    "        elif 'doble' in user_input or 'dos camas' in user_input:\n",
    "            response = \"Excelente, reservaremos una habitación doble. ¿Para cuándo agendamos su entrada? (dd/mm/aaaa)\"\n",
    "            Tipo_Cuarto = \"Doble\"\n",
    "            next_state = 'NIIA2'\n",
    "        elif 'familiar' in user_input:\n",
    "            response = \"Excelente, reservaremos una habitación familiar. ¿Para cuándo agendamos su entrada? (dd/mm/aaaa)\"\n",
    "            Tipo_Cuarto = \"Familiar\"\n",
    "            next_state = 'NIIA2'\n",
    "        elif 'deluxe' in user_input:\n",
    "            response = \"Excelente, reservaremos una habitación deluxe. ¿Para cuándo agendamos su entrada? (dd/mm/aaaa)\"\n",
    "            Tipo_Cuarto = \"Deluxe\"\n",
    "            next_state = 'NIIA2'\n",
    "        elif 'ofrecen' in user_input:\n",
    "            response = \"Ofrecemos los siguientes tipos de habitaciones: estándar, doble, familiar, suite, y deluxe.\"\n",
    "        elif user_input == 'volver':\n",
    "            next_state = 'NIIA'\n",
    "            response = \"De acuerdo, volviendo al menú anterior.\"\n",
    "        elif user_input == 'salir':\n",
    "            next_state = 'salir'\n",
    "            response = \"Hasta luego, fue un gusto ayudarte.\"\n",
    "        else:\n",
    "            next_state = 'NIIA1'\n",
    "            response = \"No he podido identificar el tipo de habitación. ¿Puedes especificar si deseas una habitación estándar, suite, doble, etc.?\"\n",
    "\n",
    "        return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.021414900Z",
     "start_time": "2023-11-06T06:23:49.988344900Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.500782Z",
     "iopub.status.busy": "2023-11-06T20:00:03.500782Z",
     "iopub.status.idle": "2023-11-06T20:00:03.512779Z",
     "shell.execute_reply": "2023-11-06T20:00:03.512779Z"
    },
    "id": "aDMr1CxZqD2p"
   },
   "outputs": [],
   "source": [
    "# nivel 2a2\n",
    "def Activar_NIIA2(user_input):\n",
    "    if user_input is None:\n",
    "        response = \"\"\n",
    "    global Fecha_entrada\n",
    "    user_input = user_input.lower()\n",
    "    \n",
    "    if user_input in despedidas_usuario:\n",
    "            response = random.choice(despedidas_chatbot)\n",
    "            return response, 'NI'\n",
    "    else:\n",
    "        try:\n",
    "            fecha_entrada_usuario = datetime.strptime(user_input, '%d/%m/%Y')\n",
    "            if fecha_entrada_usuario.date() < datetime.now().date():\n",
    "                response = \"No puedes agendar una fecha en el pasado. Por favor, elige una fecha futura.\"\n",
    "                next_state = 'NIIA2'\n",
    "            else:\n",
    "                fecha_formateada = fecha_entrada_usuario.strftime('%d de %B del %Y')\n",
    "                response = f\"Muy bien, agendaré la entrada para el {fecha_formateada}. ¿Para cuándo agendamos su salida? (dd/mm/aaaa)\"\n",
    "                Fecha_entrada = fecha_entrada_usuario\n",
    "                next_state = 'NIIA3'\n",
    "        except ValueError:\n",
    "            response = \"Parece que la fecha no está en el formato correcto. Por favor, ingresa la fecha en formato dd/mm/aaaa.\"\n",
    "            next_state = 'NIIA2'\n",
    "\n",
    "    return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.021414900Z",
     "start_time": "2023-11-06T06:23:50.004870500Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.516780Z",
     "iopub.status.busy": "2023-11-06T20:00:03.516780Z",
     "iopub.status.idle": "2023-11-06T20:00:03.527787Z",
     "shell.execute_reply": "2023-11-06T20:00:03.527787Z"
    }
   },
   "outputs": [],
   "source": [
    "# nivel2a3\n",
    "def Activar_NIIA3(user_input):\n",
    "    if user_input is None:\n",
    "        response = \"\"\n",
    "\n",
    "    global Fecha_salida\n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    if user_input in despedidas_usuario:\n",
    "            response = random.choice(despedidas_chatbot)\n",
    "            return response, 'NI'\n",
    "    else:\n",
    "        try:\n",
    "            fecha_salida_usuario = datetime.strptime(user_input, '%d/%m/%Y')\n",
    "            if fecha_salida_usuario.date() < datetime.now().date():\n",
    "                response = \"No puedes agendar una fecha de salida en el pasado. Por favor, elige una fecha futura.\"\n",
    "            else:\n",
    "                fecha_formateada = fecha_salida_usuario.strftime('%d de %B del %Y')\n",
    "                response = f\"Muy bien, agendaré la salida para el {fecha_formateada}. ¿Para cuántos huéspedes?\"\n",
    "                Fecha_salida = fecha_salida_usuario\n",
    "                next_state = 'NIIA4'\n",
    "        except ValueError:\n",
    "            response = \"Parece que la fecha no está en el formato correcto. Por favor, ingresa la fecha en formato dd/mm/aaaa.\"\n",
    "            next_state = 'NIIA3'\n",
    "\n",
    "    return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.046778300Z",
     "start_time": "2023-11-06T06:23:50.019902600Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.532292Z",
     "iopub.status.busy": "2023-11-06T20:00:03.530786Z",
     "iopub.status.idle": "2023-11-06T20:00:03.543297Z",
     "shell.execute_reply": "2023-11-06T20:00:03.543297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Nivel 2 a 4\n",
    "def Activar_NIIA4(user_input):\n",
    "    if user_input is None:\n",
    "        response = \"\"\n",
    "        return response, 'NI'\n",
    "\n",
    "    user_input = user_input.lower()\n",
    "    global Num_huespedes\n",
    "\n",
    "    Num_huespedes = user_input\n",
    "\n",
    "    if user_input in agradecimientos_usuario:\n",
    "        response = random.choice(agradecimientos_chatbot)\n",
    "        response += \"\\nReservación completada.. Presiona 'CLEAR' para continuar\"\n",
    "        return response, 'NI'\n",
    "    \n",
    "    if user_input in despedidas_usuario:\n",
    "        response = random.choice(despedidas_chatbot)\n",
    "        response += \"\\nReservación completada.. Presiona 'CLEAR' para continuar\"\n",
    "        return response, 'NI'\n",
    "    \n",
    "    if user_input == \"RESUMEN\":\n",
    "        response = \"El resumen de tu reservación es \", Tipo_Cuarto, \" de los días \", Fecha_entrada, \" a \", Fecha_salida, \" para \", Num_huespedes, \" personas.\"\n",
    "        return response, 'NI'\n",
    "    else:\n",
    "        response = \"Reservación completada.. Presiona 'CLEAR' para continuar\"\n",
    "        next_state = 'NI'\n",
    "\n",
    "    return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.079352300Z",
     "start_time": "2023-11-06T06:23:50.038262600Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.547298Z",
     "iopub.status.busy": "2023-11-06T20:00:03.547298Z",
     "iopub.status.idle": "2023-11-06T20:00:03.559298Z",
     "shell.execute_reply": "2023-11-06T20:00:03.559298Z"
    }
   },
   "outputs": [],
   "source": [
    "#nivel 2b\n",
    "def Activar_NIIB(user_input=None):\n",
    "    if user_input is None:\n",
    "        response = \"\"\n",
    "\n",
    "    if user_input in despedidas_usuario:\n",
    "            response = random.choice(despedidas_chatbot)\n",
    "            return response, 'NI'\n",
    "\n",
    "    tag, maxscore = instancer(user_input, model_NIIB, NIIB)\n",
    "\n",
    "    if maxscore > 0.2 or user_input == 'salir' or user_input == 'volver':\n",
    "        if user_input == 'volver':\n",
    "            next_state = 'NI'\n",
    "            response = \"De acuerdo, volviendo al menú anterior.\"\n",
    "        elif user_input == 'salir':\n",
    "            response = \"Hasta luego, fue un gusto hablar contigo.\"\n",
    "            next_state = 'salir'\n",
    "        elif tag == 'Apartar_espacio':\n",
    "            next_state = 'NIIB1'\n",
    "            response = \"Excelente! Apartemos un espacio. ¿Qué tipo de espacio te gustaría reservar?\"\n",
    "        elif tag == 'Servicio':\n",
    "            next_state = 'NIIB2'\n",
    "            response = \"Con gusto! ¿Qué servicio le gustaría pedir\"\n",
    "        elif tag == 'Comida_bebida':\n",
    "            next_state = 'NIIB3'\n",
    "            response = \"Hora de comer! ¿Qué alimento o bebida le gustaría pedir?\"\n",
    "        else:\n",
    "            response = \"No estoy seguro de cómo ayudarte con eso. ¿Podrías especificar más tu solicitud?\"\n",
    "            next_state = 'NIIB'\n",
    "    else:\n",
    "        response = \"Lo siento, pero no entendí. ¿Podrías ser más específico?\"\n",
    "        next_state = 'NIIB'\n",
    "\n",
    "    return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.081353800Z",
     "start_time": "2023-11-06T06:23:50.052793300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.562297Z",
     "iopub.status.busy": "2023-11-06T20:00:03.562297Z",
     "iopub.status.idle": "2023-11-06T20:00:03.575298Z",
     "shell.execute_reply": "2023-11-06T20:00:03.575298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Nivel 2b1\n",
    "def Activar_NIIB1(user_input):\n",
    "    if user_input is None:\n",
    "        response = \"Creo que no dijiste nada, ¿Qué tipo de espacio te gustaría reservar?\"\n",
    "        next_state = 'NIIB1'\n",
    "        return response, next_state\n",
    "    global Espacio_Apartado\n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    if user_input in despedidas_usuario:\n",
    "            response = random.choice(despedidas_chatbot)\n",
    "            return response, 'NI'\n",
    "    elif 'alberca' in user_input:\n",
    "        response = \"Excelente, reservaremos la alberca. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Espacio_Apartado = \"alberca\"\n",
    "        next_state = 'NI'\n",
    "    elif 'gimnasio' in user_input:\n",
    "        response = \"Excelente, reservaremos el gimnasio. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Espacio_Apartado = \"gimnasio\"\n",
    "        next_state = 'NI'\n",
    "    elif 'eventos' in user_input or 'salon' in user_input:\n",
    "        response = \"Excelente, reservaremos el salón de eventos. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Espacio_Apartado = \"salón de eventos\"\n",
    "        next_state = 'NI'\n",
    "    elif 'terraza' in user_input:\n",
    "        response = \"Excelente, reservaremos la terraza. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Espacio_Apartado = \"terraza\"\n",
    "        next_state = 'NI'\n",
    "    elif 'spa' in user_input:\n",
    "        response = \"Excelente, reservaremos el spa. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Espacio_Apartado = \"spa\"\n",
    "        next_state = 'NI'\n",
    "    else:\n",
    "        response = \"¿Podrías repetirme qué tipo de espacio te gustaría reservar?\"\n",
    "        next_state = 'NIIB1'\n",
    "\n",
    "    return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.082356500Z",
     "start_time": "2023-11-06T06:23:50.065317100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.578297Z",
     "iopub.status.busy": "2023-11-06T20:00:03.578297Z",
     "iopub.status.idle": "2023-11-06T20:00:03.590344Z",
     "shell.execute_reply": "2023-11-06T20:00:03.590344Z"
    }
   },
   "outputs": [],
   "source": [
    "#Nivel 2b2\n",
    "def Activar_NIIB2(user_input=None):\n",
    "    if user_input is None:\n",
    "        response = \"Creo que no dijiste nada, ¿Qué servicio le gustaría pedir?\"\n",
    "        next_state = 'NIIB2'\n",
    "        return response, next_state\n",
    "    global Servicio_Pedido\n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    if user_input in despedidas_usuario:\n",
    "            response = random.choice(despedidas_chatbot)\n",
    "            return response, 'NI'\n",
    "    elif user_input.count('limpiar') > 0:\n",
    "        response = \"Claro, enviaremos a alguien para limpiar la habitación. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Servicio_Pedido = \"limpieza de cuarto\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('toallas') > 0:\n",
    "        response = \"Ok, enviaremos toallas a su habitación. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Servicio_Pedido = \"toallas\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('jabón') > 0 or user_input.count('shampoo') > 0:\n",
    "        response = \"Seguro! enviaremos artículos de higiene personal a su cuarto. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Servicio_Pedido = \"higiene personal\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('equipaje') > 0 or user_input.count('maletas') > 0:\n",
    "        response = \"Mandaremos a alguien para apoyar con el equipaje. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Servicio_Pedido = \"apoyo con equipaje\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('almohadas') > 0:\n",
    "        response = \"Con gusto enviaremos más almohadas a la habitación. Si hay otro servicio que te gustaría pedir no dudes en decírmelo!\"\n",
    "        Servicio_Pedido = \"almohadas\"\n",
    "        next_state = 'NI'\n",
    "    else:\n",
    "        response = \"¿Podrías repetirme qué servicio requieres?\"\n",
    "        next_state = 'NIIB2'\n",
    "\n",
    "    return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.102389Z",
     "start_time": "2023-11-06T06:23:50.081353800Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.593383Z",
     "iopub.status.busy": "2023-11-06T20:00:03.593383Z",
     "iopub.status.idle": "2023-11-06T20:00:03.605691Z",
     "shell.execute_reply": "2023-11-06T20:00:03.605691Z"
    }
   },
   "outputs": [],
   "source": [
    "# Nivel 2b3\n",
    "def Activar_NIIB3(user_input=None):\n",
    "    if user_input is None:\n",
    "        response = \"Creo que no dijiste nada, ¿Qué alimento o bebida le gustaría pedir?\"\n",
    "        next_state = 'NIIB3'\n",
    "        return response, next_state\n",
    "\n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    global comida_pedida\n",
    "\n",
    "    if user_input in despedidas_usuario:\n",
    "            response = random.choice(despedidas_chatbot)\n",
    "            return response, 'NI'\n",
    "    elif user_input.count('desayuno') > 0:\n",
    "        response = \"Claro, enviaremos el desayuno a la habitación.\"\n",
    "        comida_pedida = \"desayuno\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('vegana') > 0 or user_input.count('vegetariana') > 0:\n",
    "        response = \"Por supuesto, prepararemos una opción vegana/vegetariana para usted.\"\n",
    "        comida_pedida = \"vegana/vegetariana\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('comida') > 0:\n",
    "        response = \"Mandaremos la comida a la habitación.\"\n",
    "        comida_pedida = \"comida\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('botella') > 0 or user_input.count('vino') > 0:\n",
    "        response = \"Seguro! enviaremos una botella de vino.\"\n",
    "        comida_pedida = \"vino\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('café') > 0:\n",
    "        response = \"Con gusto enviaremos café a su habitación.\"\n",
    "        comida_pedida = \"café\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('romántica') > 0:\n",
    "        response = \"Prepararemos una cena romántica para usted.\"\n",
    "        comida_pedida = \"romántica\"\n",
    "        next_state = 'NI'\n",
    "    elif user_input.count('cena') > 0:\n",
    "        response = \"Claro, mandaremos la cena a la habitación.\"\n",
    "        comida_pedida = \"cena\"\n",
    "        next_state = 'NI'\n",
    "    else:\n",
    "        response = \"¿Podrías repetirme qué alimento/bebida quieres pedir?\"\n",
    "        next_state = 'NIIB3'\n",
    "\n",
    "    return response, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:56:40.993042500Z",
     "start_time": "2023-11-06T06:56:40.418122200Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.608756Z",
     "iopub.status.busy": "2023-11-06T20:00:03.607754Z",
     "iopub.status.idle": "2023-11-06T20:00:03.858568Z",
     "shell.execute_reply": "2023-11-06T20:00:03.857713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementación de casos correspondientes para cada nivel del ChatBot\n",
    "# Nivel contextual inicial por defecto\n",
    "# *Variables para guardar información\n",
    "\n",
    "global Tipo_Cuarto\n",
    "global Fecha_entrada\n",
    "global Fecha_salida\n",
    "global Num_huespedes\n",
    "global Servicio_deseado\n",
    "global Espacio_Apartado\n",
    "global Servicio_Pedido\n",
    "\n",
    "Tipo_Cuarto = \"\"\n",
    "Fecha_entrada = \"\"\n",
    "Fecha_salida = \"\"\n",
    "Num_huespedes = \"\"\n",
    "Servicio_Pedido = \"\"\n",
    "Espacio_Apartado = \"\"\n",
    "Servicio_Pedido = \"\"\n",
    "comida_pedida = \"\"\n",
    "\n",
    "estado_actual = \"NI\"\n",
    "\n",
    "maquina_estados = {'NI': Activar_NI,\n",
    "                   \"NIIA\": Activar_NIIA,\n",
    "                   \"NIIA1\": Activar_NIIA1,\n",
    "                   \"NIIA2\": Activar_NIIA2,\n",
    "                   \"NIIA3\": Activar_NIIA3,\n",
    "                   \"NIIA4\": Activar_NIIA4,\n",
    "                   \"NIIB\": Activar_NIIB,\n",
    "                   \"NIIB1\": Activar_NIIB1,\n",
    "                   \"NIIB2\": Activar_NIIB2,\n",
    "                   \"NIIB3\": Activar_NIIB3\n",
    "                   }\n",
    "\n",
    "# Funciones de Gradio\n",
    "def adapted_chat1(user_input, Nivel):\n",
    "    if user_input == \"\":\n",
    "        response, next_state = maquina_estados[Nivel](None)\n",
    "    else:\n",
    "        response, next_state = maquina_estados[Nivel](user_input)\n",
    "    return response, next_state\n",
    "\n",
    "def gradio_chatbot_function(user_input, state='NI'):\n",
    "    if user_input == \"\":\n",
    "        response, next_state = adapted_chat1(None, state)\n",
    "    else:\n",
    "        response, next_state = adapted_chat1(user_input, state)\n",
    "    return response, next_state\n",
    "\n",
    "#interfaz de gradio\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_chatbot_function,\n",
    "    inputs=[gr.Textbox(lines=2, label=\"Tu mensaje\", placeholder=\"Escribe tu mensaje aquí...\"), \"state\"],\n",
    "    outputs=[gr.Textbox(label=\"Respuesta del Chatbot\", placeholder=\"Puedes preguntarme sobre reservaciones, servicios del hotel, su historia o atracciones cercanas\"), \"state\"],\n",
    "    title=\"Hotel ESDAI Chatbot\",\n",
    "    description=\"Bienvenido a Hotel ESDAI Chatbot. ¿Qué deseas hacer? Presiona CLEAR cada vez que completes lo que deseas\",\n",
    "    allow_flagging='never'\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:50.384832900Z",
     "start_time": "2023-11-06T06:23:50.326861200Z"
    },
    "execution": {
     "iopub.execute_input": "2023-11-06T20:00:03.861559Z",
     "iopub.status.busy": "2023-11-06T20:00:03.860555Z",
     "iopub.status.idle": "2023-11-06T20:00:03.873829Z",
     "shell.execute_reply": "2023-11-06T20:00:03.873017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/routes.py\", line 534, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/blocks.py\", line 1185, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/utils.py\", line 661, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_14659/1950731869.py\", line 48, in gradio_chatbot_function\n",
      "    response, next_state = adapted_chat1(user_input, state)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_14659/1950731869.py\", line 41, in adapted_chat1\n",
      "    response, next_state = maquina_estados[Nivel](user_input)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_14659/182653175.py\", line 50, in Activar_NIIA1\n",
      "    return response, next_state\n",
      "UnboundLocalError: local variable 'next_state' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 12:08:05.817547: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: indices[0,3] = 96 is not in [0, 58)\n",
      "\t [[{{node sequential_13/embedding_13/embedding_lookup}}]]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/routes.py\", line 534, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/blocks.py\", line 1185, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/utils.py\", line 661, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_14659/1950731869.py\", line 48, in gradio_chatbot_function\n",
      "    response, next_state = adapted_chat1(user_input, state)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_14659/1950731869.py\", line 41, in adapted_chat1\n",
      "    response, next_state = maquina_estados[Nivel](user_input)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_14659/182653175.py\", line 15, in Activar_NIIA1\n",
      "    tag, maxscore = instancer(user_input, model_NIIA, NIIA)\n",
      "  File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_14659/524123855.py\", line 12, in instancer\n",
      "    results = model.predict(padded)\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node 'sequential_13/embedding_13/embedding_lookup' defined at (most recent call last):\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/threading.py\", line 937, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "      self.run()\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "      result = context.run(func, *args)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/gradio/utils.py\", line 661, in wrapper\n",
      "      response = f(*args, **kwargs)\n",
      "    File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_14659/1950731869.py\", line 48, in gradio_chatbot_function\n",
      "      response, next_state = adapted_chat1(user_input, state)\n",
      "    File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_14659/1950731869.py\", line 41, in adapted_chat1\n",
      "      response, next_state = maquina_estados[Nivel](user_input)\n",
      "    File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_14659/182653175.py\", line 15, in Activar_NIIA1\n",
      "      tag, maxscore = instancer(user_input, model_NIIA, NIIA)\n",
      "    File \"/var/folders/73/m50h3qv91_n45vnh3sfw1pb00000gq/T/ipykernel_14659/524123855.py\", line 12, in instancer\n",
      "      results = model.predict(padded)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2382, in predict\n",
      "      tmp_batch_outputs = self.predict_function(iterator)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2169, in predict_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2155, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2143, in run_step\n",
      "      outputs = model.predict_step(data)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in predict_step\n",
      "      return self(x, training=False)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n",
      "      return super().call(inputs, training=training, mask=mask)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/enriquegomeztagle/anaconda3/envs/NLP/lib/python3.9/site-packages/keras/layers/core/embedding.py\", line 272, in call\n",
      "      out = tf.nn.embedding_lookup(self.embeddings, inputs)\n",
      "Node: 'sequential_13/embedding_13/embedding_lookup'\n",
      "indices[0,3] = 96 is not in [0, 58)\n",
      "\t [[{{node sequential_13/embedding_13/embedding_lookup}}]] [Op:__inference_predict_function_150583]\n"
     ]
    }
   ],
   "source": [
    "# # Check the size of the tokenizer's word index\n",
    "# print(\"Tokenizer word index size:\", len(tokenizer_NI.word_index))\n",
    "# \n",
    "# # After loading the model, check the input dimension of the embedding layer\n",
    "# embedding_input_dim = model_NIIB.layers[0].get_config()['input_dim']\n",
    "# print(\"Model's embedding input dimension:\", embedding_input_dim)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Reto 28.- Flujos conversaconales",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
